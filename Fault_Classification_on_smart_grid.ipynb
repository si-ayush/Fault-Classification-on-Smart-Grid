{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MIT2020085_Transmission_Line_Fault_Classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60H64c0ptBAK"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjvksF0B6bnN",
        "outputId": "db155007-94a0-49e7-9532-5abe92f88f8b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOWWHI_4Jbyo"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Activation\n",
        "from keras.layers import LSTM\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from matplotlib import pyplot\n",
        "\n",
        "from keras.models import model_from_json\n",
        "from keras.models import load_model\n",
        "import os\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLfcP_KPvjOg"
      },
      "source": [
        "**Reading the datasets and concatenating:-**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "fsIBOnR-w183",
        "outputId": "4b523745-8eb2-4187-8e69-c95feec24c9d"
      },
      "source": [
        "path = \"/content/gdrive/MyDrive/Colab Notebooks/Transmission/T_100.csv\"\n",
        "df_train100 = pd.read_csv(path,header = None) \n",
        "\n",
        "\n",
        "path = \"/content/gdrive/MyDrive/Colab Notebooks/Transmission/T_200.csv\"\n",
        "df_train200 = pd.read_csv(path,header = None) \n",
        "\n",
        "\n",
        "path = \"/content/gdrive/MyDrive/Colab Notebooks/Transmission/t_300.csv\"\n",
        "df_train300 = pd.read_csv(path,header = None) \n",
        "\n",
        "\n",
        "path = \"/content/gdrive/MyDrive/Colab Notebooks/Transmission/T_400.csv\"\n",
        "df_train400 = pd.read_csv(path,header = None) \n",
        "\n",
        "\n",
        "path = \"/content/gdrive/MyDrive/Colab Notebooks/Transmission/T_500.csv\"\n",
        "df_train500 = pd.read_csv(path,header = None) \n",
        "\n",
        "\n",
        "path = \"/content/gdrive/MyDrive/Colab Notebooks/Transmission/T_600.csv\"\n",
        "df_train600 = pd.read_csv(path,header = None) \n",
        "\n",
        "\n",
        "path = \"/content/gdrive/MyDrive/Colab Notebooks/Transmission/T_700.csv\"\n",
        "df_train700 = pd.read_csv(path,header = None) \n",
        "\n",
        "\n",
        "\n",
        "path = \"/content/gdrive/MyDrive/Colab Notebooks/Transmission/T_800.csv\"\n",
        "df_train800 = pd.read_csv(path,header = None) \n",
        "\n",
        "\n",
        "path = \"/content/gdrive/MyDrive/Colab Notebooks/Transmission/T_900.csv\"\n",
        "df_train900 = pd.read_csv(path,header = None) \n",
        "\n",
        "path = \"/content/gdrive/MyDrive/Colab Notebooks/Transmission/T_1000.csv\"\n",
        "df_train1000= pd.read_csv(path,header = None) \n",
        "\n",
        "\n",
        "df_merge = df_train100.append(df_train200)\n",
        "df_merge = df_merge.append(df_train300)\n",
        "df_merge = df_merge.append(df_train400)\n",
        "df_merge = df_merge.append(df_train500)\n",
        "df_merge = df_merge.append(df_train600)\n",
        "df_merge = df_merge.append(df_train700)\n",
        "df_merge = df_merge.append(df_train800)\n",
        "df_merge = df_merge.append(df_train900)\n",
        "df_merge = df_merge.append(df_train1000)\n",
        "df_merge.shape\n",
        "df_merge\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>6363</th>\n",
              "      <th>6364</th>\n",
              "      <th>6365</th>\n",
              "      <th>6366</th>\n",
              "      <th>6367</th>\n",
              "      <th>6368</th>\n",
              "      <th>6369</th>\n",
              "      <th>6370</th>\n",
              "      <th>6371</th>\n",
              "      <th>6372</th>\n",
              "      <th>6373</th>\n",
              "      <th>6374</th>\n",
              "      <th>6375</th>\n",
              "      <th>6376</th>\n",
              "      <th>6377</th>\n",
              "      <th>6378</th>\n",
              "      <th>6379</th>\n",
              "      <th>6380</th>\n",
              "      <th>6381</th>\n",
              "      <th>6382</th>\n",
              "      <th>6383</th>\n",
              "      <th>6384</th>\n",
              "      <th>6385</th>\n",
              "      <th>6386</th>\n",
              "      <th>6387</th>\n",
              "      <th>6388</th>\n",
              "      <th>6389</th>\n",
              "      <th>6390</th>\n",
              "      <th>6391</th>\n",
              "      <th>6392</th>\n",
              "      <th>6393</th>\n",
              "      <th>6394</th>\n",
              "      <th>6395</th>\n",
              "      <th>6396</th>\n",
              "      <th>6397</th>\n",
              "      <th>6398</th>\n",
              "      <th>6399</th>\n",
              "      <th>6400</th>\n",
              "      <th>6401</th>\n",
              "      <th>6402</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>0.478</td>\n",
              "      <td>-0.428</td>\n",
              "      <td>-0.050</td>\n",
              "      <td>0.000609</td>\n",
              "      <td>0.000175</td>\n",
              "      <td>-0.000784</td>\n",
              "      <td>1.039</td>\n",
              "      <td>-0.792</td>\n",
              "      <td>-0.247</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>5.830000e-04</td>\n",
              "      <td>-0.002000</td>\n",
              "      <td>0.957</td>\n",
              "      <td>-0.537</td>\n",
              "      <td>-0.420</td>\n",
              "      <td>0.000686</td>\n",
              "      <td>0.000815</td>\n",
              "      <td>-0.002000</td>\n",
              "      <td>1.019</td>\n",
              "      <td>-0.433</td>\n",
              "      <td>-0.585</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>-0.002000</td>\n",
              "      <td>0.943</td>\n",
              "      <td>-0.218</td>\n",
              "      <td>-0.725</td>\n",
              "      <td>0.000159</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>-0.001000</td>\n",
              "      <td>0.898</td>\n",
              "      <td>-0.055</td>\n",
              "      <td>-0.843</td>\n",
              "      <td>-0.000102</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>-0.001000</td>\n",
              "      <td>0.780</td>\n",
              "      <td>0.148</td>\n",
              "      <td>-0.928</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>0.479</td>\n",
              "      <td>-0.426</td>\n",
              "      <td>-0.053</td>\n",
              "      <td>0.000606</td>\n",
              "      <td>0.000180</td>\n",
              "      <td>-0.000786</td>\n",
              "      <td>1.041</td>\n",
              "      <td>-0.787</td>\n",
              "      <td>-0.254</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>5.930000e-04</td>\n",
              "      <td>-0.002000</td>\n",
              "      <td>0.957</td>\n",
              "      <td>-0.532</td>\n",
              "      <td>-0.426</td>\n",
              "      <td>0.000678</td>\n",
              "      <td>0.000823</td>\n",
              "      <td>-0.002000</td>\n",
              "      <td>1.018</td>\n",
              "      <td>-0.427</td>\n",
              "      <td>-0.590</td>\n",
              "      <td>0.000492</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>-0.002000</td>\n",
              "      <td>0.942</td>\n",
              "      <td>-0.212</td>\n",
              "      <td>-0.730</td>\n",
              "      <td>0.000149</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>-0.001000</td>\n",
              "      <td>0.895</td>\n",
              "      <td>-0.049</td>\n",
              "      <td>-0.846</td>\n",
              "      <td>-0.000112</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>-0.001000</td>\n",
              "      <td>0.776</td>\n",
              "      <td>0.154</td>\n",
              "      <td>-0.930</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>0.503</td>\n",
              "      <td>-0.383</td>\n",
              "      <td>-0.120</td>\n",
              "      <td>0.000528</td>\n",
              "      <td>0.000282</td>\n",
              "      <td>-0.000810</td>\n",
              "      <td>1.072</td>\n",
              "      <td>-0.684</td>\n",
              "      <td>-0.388</td>\n",
              "      <td>0.000906</td>\n",
              "      <td>7.920000e-04</td>\n",
              "      <td>-0.002000</td>\n",
              "      <td>0.957</td>\n",
              "      <td>-0.425</td>\n",
              "      <td>-0.532</td>\n",
              "      <td>0.000499</td>\n",
              "      <td>0.000977</td>\n",
              "      <td>-0.001000</td>\n",
              "      <td>0.998</td>\n",
              "      <td>-0.305</td>\n",
              "      <td>-0.693</td>\n",
              "      <td>0.000291</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>-0.002000</td>\n",
              "      <td>0.895</td>\n",
              "      <td>-0.086</td>\n",
              "      <td>-0.809</td>\n",
              "      <td>-0.000050</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>-0.001000</td>\n",
              "      <td>0.829</td>\n",
              "      <td>0.080</td>\n",
              "      <td>-0.909</td>\n",
              "      <td>-0.000312</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>-0.001000</td>\n",
              "      <td>0.690</td>\n",
              "      <td>0.279</td>\n",
              "      <td>-0.969</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.279</td>\n",
              "      <td>0.246</td>\n",
              "      <td>-0.525</td>\n",
              "      <td>-0.000469</td>\n",
              "      <td>0.000820</td>\n",
              "      <td>-0.000351</td>\n",
              "      <td>0.448</td>\n",
              "      <td>0.632</td>\n",
              "      <td>-1.080</td>\n",
              "      <td>-0.001000</td>\n",
              "      <td>2.000000e-03</td>\n",
              "      <td>-0.000511</td>\n",
              "      <td>0.193</td>\n",
              "      <td>0.718</td>\n",
              "      <td>-0.911</td>\n",
              "      <td>-0.001000</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>-0.000123</td>\n",
              "      <td>0.047</td>\n",
              "      <td>0.861</td>\n",
              "      <td>-0.908</td>\n",
              "      <td>-0.001000</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.000119</td>\n",
              "      <td>-0.166</td>\n",
              "      <td>0.926</td>\n",
              "      <td>-0.760</td>\n",
              "      <td>-0.002000</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.000441</td>\n",
              "      <td>-0.332</td>\n",
              "      <td>0.989</td>\n",
              "      <td>-0.657</td>\n",
              "      <td>-0.002000</td>\n",
              "      <td>0.000878</td>\n",
              "      <td>0.000695</td>\n",
              "      <td>-0.513</td>\n",
              "      <td>0.997</td>\n",
              "      <td>-0.484</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0.049</td>\n",
              "      <td>0.429</td>\n",
              "      <td>-0.477</td>\n",
              "      <td>-0.000724</td>\n",
              "      <td>0.000702</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>-0.046</td>\n",
              "      <td>0.962</td>\n",
              "      <td>-0.916</td>\n",
              "      <td>-0.002000</td>\n",
              "      <td>1.000000e-03</td>\n",
              "      <td>0.000275</td>\n",
              "      <td>-0.252</td>\n",
              "      <td>0.928</td>\n",
              "      <td>-0.675</td>\n",
              "      <td>-0.001000</td>\n",
              "      <td>0.000924</td>\n",
              "      <td>0.000566</td>\n",
              "      <td>-0.419</td>\n",
              "      <td>1.017</td>\n",
              "      <td>-0.598</td>\n",
              "      <td>-0.002000</td>\n",
              "      <td>0.000776</td>\n",
              "      <td>0.000827</td>\n",
              "      <td>-0.588</td>\n",
              "      <td>0.981</td>\n",
              "      <td>-0.394</td>\n",
              "      <td>-0.002000</td>\n",
              "      <td>0.000443</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>-0.725</td>\n",
              "      <td>0.967</td>\n",
              "      <td>-0.242</td>\n",
              "      <td>-0.001000</td>\n",
              "      <td>0.000193</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>-0.844</td>\n",
              "      <td>0.882</td>\n",
              "      <td>-0.039</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>10</td>\n",
              "      <td>-0.327</td>\n",
              "      <td>-0.192</td>\n",
              "      <td>0.520</td>\n",
              "      <td>-0.000140</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000119</td>\n",
              "      <td>-0.556</td>\n",
              "      <td>-0.530</td>\n",
              "      <td>1.085</td>\n",
              "      <td>-0.000270</td>\n",
              "      <td>2.360000e-07</td>\n",
              "      <td>0.000270</td>\n",
              "      <td>-0.296</td>\n",
              "      <td>-0.642</td>\n",
              "      <td>0.938</td>\n",
              "      <td>-0.000202</td>\n",
              "      <td>-0.000061</td>\n",
              "      <td>0.000263</td>\n",
              "      <td>-0.160</td>\n",
              "      <td>-0.795</td>\n",
              "      <td>0.955</td>\n",
              "      <td>-0.000182</td>\n",
              "      <td>-0.000109</td>\n",
              "      <td>0.000291</td>\n",
              "      <td>0.057</td>\n",
              "      <td>-0.883</td>\n",
              "      <td>0.826</td>\n",
              "      <td>-0.000124</td>\n",
              "      <td>-0.000159</td>\n",
              "      <td>0.000283</td>\n",
              "      <td>0.224</td>\n",
              "      <td>-0.962</td>\n",
              "      <td>0.737</td>\n",
              "      <td>-0.000081</td>\n",
              "      <td>-0.000199</td>\n",
              "      <td>0.000281</td>\n",
              "      <td>0.415</td>\n",
              "      <td>-0.993</td>\n",
              "      <td>0.578</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>10</td>\n",
              "      <td>-0.098</td>\n",
              "      <td>-0.398</td>\n",
              "      <td>0.496</td>\n",
              "      <td>-0.000098</td>\n",
              "      <td>-0.000051</td>\n",
              "      <td>0.000149</td>\n",
              "      <td>-0.058</td>\n",
              "      <td>-0.910</td>\n",
              "      <td>0.968</td>\n",
              "      <td>-0.000169</td>\n",
              "      <td>-1.440000e-04</td>\n",
              "      <td>0.000312</td>\n",
              "      <td>0.162</td>\n",
              "      <td>-0.900</td>\n",
              "      <td>0.738</td>\n",
              "      <td>-0.000094</td>\n",
              "      <td>-0.000178</td>\n",
              "      <td>0.000272</td>\n",
              "      <td>0.328</td>\n",
              "      <td>-1.003</td>\n",
              "      <td>0.675</td>\n",
              "      <td>-0.000056</td>\n",
              "      <td>-0.000223</td>\n",
              "      <td>0.000279</td>\n",
              "      <td>0.509</td>\n",
              "      <td>-0.988</td>\n",
              "      <td>0.479</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>-0.000250</td>\n",
              "      <td>0.000243</td>\n",
              "      <td>0.655</td>\n",
              "      <td>-0.989</td>\n",
              "      <td>0.334</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>-0.000274</td>\n",
              "      <td>0.000219</td>\n",
              "      <td>0.789</td>\n",
              "      <td>-0.923</td>\n",
              "      <td>0.134</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>10</td>\n",
              "      <td>0.519</td>\n",
              "      <td>-0.330</td>\n",
              "      <td>-0.190</td>\n",
              "      <td>0.000119</td>\n",
              "      <td>-0.000140</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>1.085</td>\n",
              "      <td>-0.561</td>\n",
              "      <td>-0.525</td>\n",
              "      <td>0.000269</td>\n",
              "      <td>-2.720000e-04</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.939</td>\n",
              "      <td>-0.301</td>\n",
              "      <td>-0.639</td>\n",
              "      <td>0.000263</td>\n",
              "      <td>-0.000204</td>\n",
              "      <td>-0.000059</td>\n",
              "      <td>0.957</td>\n",
              "      <td>-0.166</td>\n",
              "      <td>-0.791</td>\n",
              "      <td>0.000291</td>\n",
              "      <td>-0.000184</td>\n",
              "      <td>-0.000107</td>\n",
              "      <td>0.829</td>\n",
              "      <td>0.052</td>\n",
              "      <td>-0.881</td>\n",
              "      <td>0.000284</td>\n",
              "      <td>-0.000127</td>\n",
              "      <td>-0.000157</td>\n",
              "      <td>0.741</td>\n",
              "      <td>0.219</td>\n",
              "      <td>-0.960</td>\n",
              "      <td>0.000282</td>\n",
              "      <td>-0.000084</td>\n",
              "      <td>-0.000198</td>\n",
              "      <td>0.582</td>\n",
              "      <td>0.410</td>\n",
              "      <td>-0.993</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>10</td>\n",
              "      <td>-0.299</td>\n",
              "      <td>0.524</td>\n",
              "      <td>-0.224</td>\n",
              "      <td>-0.000015</td>\n",
              "      <td>0.000137</td>\n",
              "      <td>-0.000123</td>\n",
              "      <td>-0.733</td>\n",
              "      <td>1.060</td>\n",
              "      <td>-0.327</td>\n",
              "      <td>-0.000072</td>\n",
              "      <td>2.980000e-04</td>\n",
              "      <td>-0.000227</td>\n",
              "      <td>-0.789</td>\n",
              "      <td>0.868</td>\n",
              "      <td>-0.079</td>\n",
              "      <td>-0.000121</td>\n",
              "      <td>0.000275</td>\n",
              "      <td>-0.000153</td>\n",
              "      <td>-0.921</td>\n",
              "      <td>0.845</td>\n",
              "      <td>0.075</td>\n",
              "      <td>-0.000169</td>\n",
              "      <td>0.000292</td>\n",
              "      <td>-0.000124</td>\n",
              "      <td>-0.961</td>\n",
              "      <td>0.679</td>\n",
              "      <td>0.281</td>\n",
              "      <td>-0.000209</td>\n",
              "      <td>0.000270</td>\n",
              "      <td>-0.000062</td>\n",
              "      <td>-1.004</td>\n",
              "      <td>0.561</td>\n",
              "      <td>0.444</td>\n",
              "      <td>-0.000242</td>\n",
              "      <td>0.000257</td>\n",
              "      <td>-0.000015</td>\n",
              "      <td>-0.988</td>\n",
              "      <td>0.376</td>\n",
              "      <td>0.612</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>10</td>\n",
              "      <td>-0.139</td>\n",
              "      <td>-0.370</td>\n",
              "      <td>0.508</td>\n",
              "      <td>-0.000107</td>\n",
              "      <td>-0.000039</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>-0.143</td>\n",
              "      <td>-0.860</td>\n",
              "      <td>1.003</td>\n",
              "      <td>-0.000190</td>\n",
              "      <td>-1.210000e-04</td>\n",
              "      <td>0.000311</td>\n",
              "      <td>0.088</td>\n",
              "      <td>-0.871</td>\n",
              "      <td>0.784</td>\n",
              "      <td>-0.000115</td>\n",
              "      <td>-0.000161</td>\n",
              "      <td>0.000275</td>\n",
              "      <td>0.251</td>\n",
              "      <td>-0.984</td>\n",
              "      <td>0.733</td>\n",
              "      <td>-0.000079</td>\n",
              "      <td>-0.000207</td>\n",
              "      <td>0.000286</td>\n",
              "      <td>0.441</td>\n",
              "      <td>-0.986</td>\n",
              "      <td>0.545</td>\n",
              "      <td>-0.000016</td>\n",
              "      <td>-0.000238</td>\n",
              "      <td>0.000254</td>\n",
              "      <td>0.593</td>\n",
              "      <td>-1.001</td>\n",
              "      <td>0.408</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>-0.000266</td>\n",
              "      <td>0.000234</td>\n",
              "      <td>0.739</td>\n",
              "      <td>-0.949</td>\n",
              "      <td>0.211</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5500 rows × 6403 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0      1      2      3         4     ...  6398  6399  6400  6401  6402\n",
              "0       6  0.478 -0.428 -0.050  0.000609  ...   NaN   NaN   NaN   NaN   NaN\n",
              "1       6  0.479 -0.426 -0.053  0.000606  ...   NaN   NaN   NaN   NaN   NaN\n",
              "2       5  0.503 -0.383 -0.120  0.000528  ...   NaN   NaN   NaN   NaN   NaN\n",
              "3       1  0.279  0.246 -0.525 -0.000469  ...   NaN   NaN   NaN   NaN   NaN\n",
              "4       1  0.049  0.429 -0.477 -0.000724  ...   NaN   NaN   NaN   NaN   NaN\n",
              "..    ...    ...    ...    ...       ...  ...   ...   ...   ...   ...   ...\n",
              "995    10 -0.327 -0.192  0.520 -0.000140  ...   NaN   NaN   NaN   NaN   NaN\n",
              "996    10 -0.098 -0.398  0.496 -0.000098  ...   NaN   NaN   NaN   NaN   NaN\n",
              "997    10  0.519 -0.330 -0.190  0.000119  ...   NaN   NaN   NaN   NaN   NaN\n",
              "998    10 -0.299  0.524 -0.224 -0.000015  ...   NaN   NaN   NaN   NaN   NaN\n",
              "999    10 -0.139 -0.370  0.508 -0.000107  ...   NaN   NaN   NaN   NaN   NaN\n",
              "\n",
              "[5500 rows x 6403 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 586
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kU_eA4vOJnvQ",
        "outputId": "a3c12ae3-029c-4b72-d9fa-6e2c9758f6f1"
      },
      "source": [
        "print(df_merge)\n",
        "print(df_merge.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     0      1      2      3         4     ...  6398  6399  6400  6401  6402\n",
            "0       6  0.478 -0.428 -0.050  0.000609  ...   NaN   NaN   NaN   NaN   NaN\n",
            "1       6  0.479 -0.426 -0.053  0.000606  ...   NaN   NaN   NaN   NaN   NaN\n",
            "2       5  0.503 -0.383 -0.120  0.000528  ...   NaN   NaN   NaN   NaN   NaN\n",
            "3       1  0.279  0.246 -0.525 -0.000469  ...   NaN   NaN   NaN   NaN   NaN\n",
            "4       1  0.049  0.429 -0.477 -0.000724  ...   NaN   NaN   NaN   NaN   NaN\n",
            "..    ...    ...    ...    ...       ...  ...   ...   ...   ...   ...   ...\n",
            "995    10 -0.327 -0.192  0.520 -0.000140  ...   NaN   NaN   NaN   NaN   NaN\n",
            "996    10 -0.098 -0.398  0.496 -0.000098  ...   NaN   NaN   NaN   NaN   NaN\n",
            "997    10  0.519 -0.330 -0.190  0.000119  ...   NaN   NaN   NaN   NaN   NaN\n",
            "998    10 -0.299  0.524 -0.224 -0.000015  ...   NaN   NaN   NaN   NaN   NaN\n",
            "999    10 -0.139 -0.370  0.508 -0.000107  ...   NaN   NaN   NaN   NaN   NaN\n",
            "\n",
            "[5500 rows x 6403 columns]\n",
            "(5500, 6403)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieoMNtA-KpG-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3239cd1b-62da-41ab-adf7-2e5654f9f886"
      },
      "source": [
        "X = df_merge.iloc[:5500,1:6403].values\n",
        "y = df_merge.iloc[:5500,0].values\n",
        "print(X)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.478 -0.428 -0.05  ...    nan    nan    nan]\n",
            " [ 0.479 -0.426 -0.053 ...    nan    nan    nan]\n",
            " [ 0.503 -0.383 -0.12  ...    nan    nan    nan]\n",
            " ...\n",
            " [ 0.519 -0.33  -0.19  ...    nan    nan    nan]\n",
            " [-0.299  0.524 -0.224 ...    nan    nan    nan]\n",
            " [-0.139 -0.37   0.508 ...    nan    nan    nan]]\n",
            "[ 6  6  5 ... 10 10 10]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISL4ReHlLBwh",
        "outputId": "c68a549b-9ef9-48d6-f2fb-cc13659c5ecf"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imputer.fit(X[:5500,0:])\n",
        "X[:5500,0:] = imputer.transform(X[:5500,0:])\n",
        "\n",
        "print('\\n Dataset after removing missing values : \\n' ,X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Dataset after removing missing values : \n",
            " [[ 4.78000000e-01 -4.28000000e-01 -5.00000000e-02 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]\n",
            " [ 4.79000000e-01 -4.26000000e-01 -5.30000000e-02 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]\n",
            " [ 5.03000000e-01 -3.83000000e-01 -1.20000000e-01 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]\n",
            " ...\n",
            " [ 5.19000000e-01 -3.30000000e-01 -1.90000000e-01 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]\n",
            " [-2.99000000e-01  5.24000000e-01 -2.24000000e-01 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]\n",
            " [-1.39000000e-01 -3.70000000e-01  5.08000000e-01 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-JKTNuTLPJh"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjlH0lcjLS3R",
        "outputId": "01524e4c-8c09-4f61-a274-cdb7a1987f03"
      },
      "source": [
        "print(X_train)\n",
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 3.72000000e-01 -5.07000000e-01  1.36000000e-01 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]\n",
            " [-1.05000000e-01 -3.93000000e-01  4.98000000e-01 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]\n",
            " [-4.85000000e-01  6.80000000e-02  4.17000000e-01 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]\n",
            " ...\n",
            " [ 5.80000000e-02  4.23000000e-01 -4.81000000e-01 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]\n",
            " [ 4.21000000e-01  6.10000000e-02 -4.83000000e-01 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]\n",
            " [-1.51000000e-01 -3.60000000e-01  5.11000000e-01 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]]\n",
            "(4125, 6402)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LvS__3NLYKf",
        "outputId": "eb418efe-c159-4f82-e7d2-ad3450ec105f"
      },
      "source": [
        "print(y_train)\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 9  2  4 ...  1  7 10]\n",
            "(4125,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1YC96uxLcm4",
        "outputId": "edb2e59e-4cbd-4fe7-dc96-440698eb5838"
      },
      "source": [
        "print(X_test)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 4.92000000e-01 -4.06000000e-01 -8.60000000e-02 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]\n",
            " [-2.90000000e-01 -2.35000000e-01  5.25000000e-01 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]\n",
            " [ 4.56000000e-01 -4.54000000e-01 -3.00000000e-03 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]\n",
            " ...\n",
            " [-2.07000000e-01  5.22000000e-01 -3.14000000e-01 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]\n",
            " [ 4.38000000e-01 -4.70000000e-01  3.20000000e-02 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]\n",
            " [ 4.85000000e-01 -4.17000000e-01 -6.90000000e-02 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]]\n",
            "(1375, 6402)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NyVNpmlLfgt",
        "outputId": "19765cfa-df09-464c-ef89-5dd890202d5c"
      },
      "source": [
        "print(y_test)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7 1 1 ... 7 1 4]\n",
            "(1375,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsoX8ICRLkwt",
        "outputId": "28e9c772-9015-4c22-dcac-070e59e628af"
      },
      "source": [
        "print(X_train)\n",
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 3.72000000e-01 -5.07000000e-01  1.36000000e-01 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]\n",
            " [-1.05000000e-01 -3.93000000e-01  4.98000000e-01 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]\n",
            " [-4.85000000e-01  6.80000000e-02  4.17000000e-01 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]\n",
            " ...\n",
            " [ 5.80000000e-02  4.23000000e-01 -4.81000000e-01 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]\n",
            " [ 4.21000000e-01  6.10000000e-02 -4.83000000e-01 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]\n",
            " [-1.51000000e-01 -3.60000000e-01  5.11000000e-01 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]]\n",
            "(4125, 6402)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAKxg4_LLoP4",
        "outputId": "b86b72d1-62ad-4e0f-e616-5de6be347e1a"
      },
      "source": [
        "print(X_test)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 4.92000000e-01 -4.06000000e-01 -8.60000000e-02 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]\n",
            " [-2.90000000e-01 -2.35000000e-01  5.25000000e-01 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]\n",
            " [ 4.56000000e-01 -4.54000000e-01 -3.00000000e-03 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]\n",
            " ...\n",
            " [-2.07000000e-01  5.22000000e-01 -3.14000000e-01 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]\n",
            " [ 4.38000000e-01 -4.70000000e-01  3.20000000e-02 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]\n",
            " [ 4.85000000e-01 -4.17000000e-01 -6.90000000e-02 ...  9.39666667e-05\n",
            "   7.15000000e-05 -2.05000000e-04]]\n",
            "(1375, 6402)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4u4IDMnLq4c",
        "outputId": "5966e701-5d16-428e-d086-90c4428a7ef9"
      },
      "source": [
        "X_train = X_train.reshape(4125,1,6402)\n",
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4125, 1, 6402)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JTnUvdmMM5-",
        "outputId": "9215dde4-9c56-41e1-ee96-28c0e9a97e92"
      },
      "source": [
        "X_test = X_test.reshape(1375,1,6402)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1375, 1, 6402)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMVWBjrIMka0",
        "outputId": "7f796218-a1b4-480c-c62c-c93b16b53556"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4125, 1, 6402)\n",
            "(4125,)\n",
            "(1375, 1, 6402)\n",
            "(1375,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83pqfa_2NDFr",
        "outputId": "7a70aeb8-9d5d-4dcc-dd85-be9c8c2783ba"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences = True))\n",
        "model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dense(1))\n",
        "opt = optimizers.Adadelta(lr=0.25, decay=1e-6, )\n",
        "model.compile(loss='mae', optimizer=opt, metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=1000, batch_size=128, validation_data=(X_test, y_test),verbose=1, shuffle=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_52 (LSTM)               (None, 1, 128)            3343872   \n",
            "_________________________________________________________________\n",
            "lstm_53 (LSTM)               (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 3,475,585\n",
            "Trainable params: 3,475,585\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/1000\n",
            "33/33 [==============================] - 3s 31ms/step - loss: 4.8313 - accuracy: 0.0137 - val_loss: 3.2209 - val_accuracy: 0.1869\n",
            "Epoch 2/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 2.7155 - accuracy: 0.1841 - val_loss: 2.0202 - val_accuracy: 0.1884\n",
            "Epoch 3/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 1.8445 - accuracy: 0.1823 - val_loss: 1.5779 - val_accuracy: 0.1796\n",
            "Epoch 4/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 1.5062 - accuracy: 0.1677 - val_loss: 1.4075 - val_accuracy: 0.1658\n",
            "Epoch 5/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 1.3610 - accuracy: 0.1615 - val_loss: 1.3118 - val_accuracy: 0.1709\n",
            "Epoch 6/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 1.2522 - accuracy: 0.1646 - val_loss: 1.1804 - val_accuracy: 0.1695\n",
            "Epoch 7/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 1.1430 - accuracy: 0.1698 - val_loss: 1.1533 - val_accuracy: 0.1673\n",
            "Epoch 8/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 1.0558 - accuracy: 0.1759 - val_loss: 1.1290 - val_accuracy: 0.1542\n",
            "Epoch 9/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.9402 - accuracy: 0.1741 - val_loss: 1.2529 - val_accuracy: 0.1745\n",
            "Epoch 10/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.9099 - accuracy: 0.1784 - val_loss: 0.9852 - val_accuracy: 0.1702\n",
            "Epoch 11/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.8700 - accuracy: 0.1731 - val_loss: 1.1016 - val_accuracy: 0.1789\n",
            "Epoch 12/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.8168 - accuracy: 0.1816 - val_loss: 1.1517 - val_accuracy: 0.1709\n",
            "Epoch 13/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.7737 - accuracy: 0.1802 - val_loss: 0.9796 - val_accuracy: 0.1418\n",
            "Epoch 14/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.7397 - accuracy: 0.1728 - val_loss: 1.0680 - val_accuracy: 0.1789\n",
            "Epoch 15/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.7301 - accuracy: 0.1807 - val_loss: 0.7448 - val_accuracy: 0.1855\n",
            "Epoch 16/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.6563 - accuracy: 0.1785 - val_loss: 0.8040 - val_accuracy: 0.1716\n",
            "Epoch 17/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.6538 - accuracy: 0.1806 - val_loss: 1.0700 - val_accuracy: 0.1869\n",
            "Epoch 18/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.6908 - accuracy: 0.1820 - val_loss: 0.8874 - val_accuracy: 0.1629\n",
            "Epoch 19/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.6626 - accuracy: 0.1786 - val_loss: 0.8340 - val_accuracy: 0.1789\n",
            "Epoch 20/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.6049 - accuracy: 0.1814 - val_loss: 0.7507 - val_accuracy: 0.1869\n",
            "Epoch 21/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.5952 - accuracy: 0.1814 - val_loss: 0.9490 - val_accuracy: 0.1644\n",
            "Epoch 22/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.6161 - accuracy: 0.1803 - val_loss: 0.9468 - val_accuracy: 0.1418\n",
            "Epoch 23/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.6135 - accuracy: 0.1796 - val_loss: 0.7634 - val_accuracy: 0.1840\n",
            "Epoch 24/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.5673 - accuracy: 0.1827 - val_loss: 0.7224 - val_accuracy: 0.1760\n",
            "Epoch 25/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.5390 - accuracy: 0.1823 - val_loss: 0.6310 - val_accuracy: 0.1869\n",
            "Epoch 26/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.5028 - accuracy: 0.1837 - val_loss: 0.7358 - val_accuracy: 0.1855\n",
            "Epoch 27/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.5386 - accuracy: 0.1801 - val_loss: 0.7540 - val_accuracy: 0.1789\n",
            "Epoch 28/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.5194 - accuracy: 0.1834 - val_loss: 0.8269 - val_accuracy: 0.1651\n",
            "Epoch 29/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.5263 - accuracy: 0.1809 - val_loss: 0.8269 - val_accuracy: 0.1731\n",
            "Epoch 30/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.5128 - accuracy: 0.1810 - val_loss: 0.6549 - val_accuracy: 0.1833\n",
            "Epoch 31/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.4978 - accuracy: 0.1823 - val_loss: 0.6734 - val_accuracy: 0.1789\n",
            "Epoch 32/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.4797 - accuracy: 0.1834 - val_loss: 0.6934 - val_accuracy: 0.1702\n",
            "Epoch 33/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.4682 - accuracy: 0.1824 - val_loss: 0.6115 - val_accuracy: 0.1847\n",
            "Epoch 34/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.4695 - accuracy: 0.1834 - val_loss: 0.8267 - val_accuracy: 0.1855\n",
            "Epoch 35/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.4746 - accuracy: 0.1822 - val_loss: 0.6488 - val_accuracy: 0.1767\n",
            "Epoch 36/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.4583 - accuracy: 0.1814 - val_loss: 0.7834 - val_accuracy: 0.1804\n",
            "Epoch 37/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.4545 - accuracy: 0.1803 - val_loss: 0.6134 - val_accuracy: 0.1825\n",
            "Epoch 38/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.4335 - accuracy: 0.1831 - val_loss: 0.5821 - val_accuracy: 0.1818\n",
            "Epoch 39/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.4474 - accuracy: 0.1824 - val_loss: 0.7207 - val_accuracy: 0.1804\n",
            "Epoch 40/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.4425 - accuracy: 0.1820 - val_loss: 0.7700 - val_accuracy: 0.1840\n",
            "Epoch 41/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.4343 - accuracy: 0.1807 - val_loss: 0.6439 - val_accuracy: 0.1745\n",
            "Epoch 42/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.4271 - accuracy: 0.1825 - val_loss: 0.6669 - val_accuracy: 0.1818\n",
            "Epoch 43/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.4152 - accuracy: 0.1801 - val_loss: 0.6626 - val_accuracy: 0.1724\n",
            "Epoch 44/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.4063 - accuracy: 0.1805 - val_loss: 0.7281 - val_accuracy: 0.1695\n",
            "Epoch 45/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.4110 - accuracy: 0.1791 - val_loss: 0.6147 - val_accuracy: 0.1869\n",
            "Epoch 46/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.4114 - accuracy: 0.1821 - val_loss: 0.6305 - val_accuracy: 0.1716\n",
            "Epoch 47/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.4188 - accuracy: 0.1803 - val_loss: 0.5971 - val_accuracy: 0.1847\n",
            "Epoch 48/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3937 - accuracy: 0.1827 - val_loss: 0.7898 - val_accuracy: 0.1695\n",
            "Epoch 49/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.4107 - accuracy: 0.1786 - val_loss: 0.5943 - val_accuracy: 0.1855\n",
            "Epoch 50/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.3992 - accuracy: 0.1817 - val_loss: 0.5970 - val_accuracy: 0.1760\n",
            "Epoch 51/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3855 - accuracy: 0.1808 - val_loss: 0.6680 - val_accuracy: 0.1753\n",
            "Epoch 52/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.3787 - accuracy: 0.1803 - val_loss: 0.6305 - val_accuracy: 0.1840\n",
            "Epoch 53/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3658 - accuracy: 0.1814 - val_loss: 0.5347 - val_accuracy: 0.1796\n",
            "Epoch 54/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3756 - accuracy: 0.1806 - val_loss: 0.6931 - val_accuracy: 0.1760\n",
            "Epoch 55/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3774 - accuracy: 0.1787 - val_loss: 0.5832 - val_accuracy: 0.1847\n",
            "Epoch 56/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3618 - accuracy: 0.1820 - val_loss: 0.5831 - val_accuracy: 0.1716\n",
            "Epoch 57/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.3602 - accuracy: 0.1810 - val_loss: 0.6791 - val_accuracy: 0.1782\n",
            "Epoch 58/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3755 - accuracy: 0.1802 - val_loss: 0.6423 - val_accuracy: 0.1702\n",
            "Epoch 59/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3500 - accuracy: 0.1780 - val_loss: 0.5719 - val_accuracy: 0.1811\n",
            "Epoch 60/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3593 - accuracy: 0.1808 - val_loss: 0.6268 - val_accuracy: 0.1855\n",
            "Epoch 61/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3687 - accuracy: 0.1810 - val_loss: 0.5828 - val_accuracy: 0.1731\n",
            "Epoch 62/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3444 - accuracy: 0.1789 - val_loss: 0.6689 - val_accuracy: 0.1796\n",
            "Epoch 63/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3536 - accuracy: 0.1795 - val_loss: 0.5439 - val_accuracy: 0.1782\n",
            "Epoch 64/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.3579 - accuracy: 0.1802 - val_loss: 0.5657 - val_accuracy: 0.1745\n",
            "Epoch 65/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3336 - accuracy: 0.1791 - val_loss: 0.6485 - val_accuracy: 0.1724\n",
            "Epoch 66/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3449 - accuracy: 0.1797 - val_loss: 0.5199 - val_accuracy: 0.1818\n",
            "Epoch 67/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3262 - accuracy: 0.1803 - val_loss: 0.6691 - val_accuracy: 0.1709\n",
            "Epoch 68/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3374 - accuracy: 0.1782 - val_loss: 0.5969 - val_accuracy: 0.1825\n",
            "Epoch 69/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3233 - accuracy: 0.1804 - val_loss: 0.5102 - val_accuracy: 0.1833\n",
            "Epoch 70/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.3372 - accuracy: 0.1796 - val_loss: 0.6025 - val_accuracy: 0.1709\n",
            "Epoch 71/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3239 - accuracy: 0.1783 - val_loss: 0.5381 - val_accuracy: 0.1840\n",
            "Epoch 72/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.3166 - accuracy: 0.1785 - val_loss: 0.5668 - val_accuracy: 0.1738\n",
            "Epoch 73/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3218 - accuracy: 0.1788 - val_loss: 0.4969 - val_accuracy: 0.1833\n",
            "Epoch 74/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3013 - accuracy: 0.1797 - val_loss: 0.5456 - val_accuracy: 0.1833\n",
            "Epoch 75/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3320 - accuracy: 0.1804 - val_loss: 0.4901 - val_accuracy: 0.1833\n",
            "Epoch 76/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3032 - accuracy: 0.1798 - val_loss: 0.6303 - val_accuracy: 0.1825\n",
            "Epoch 77/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.3109 - accuracy: 0.1793 - val_loss: 0.6031 - val_accuracy: 0.1753\n",
            "Epoch 78/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2998 - accuracy: 0.1787 - val_loss: 0.5232 - val_accuracy: 0.1767\n",
            "Epoch 79/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2934 - accuracy: 0.1802 - val_loss: 0.6304 - val_accuracy: 0.1753\n",
            "Epoch 80/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3135 - accuracy: 0.1783 - val_loss: 0.4818 - val_accuracy: 0.1833\n",
            "Epoch 81/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2809 - accuracy: 0.1805 - val_loss: 0.5266 - val_accuracy: 0.1753\n",
            "Epoch 82/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2935 - accuracy: 0.1792 - val_loss: 0.5579 - val_accuracy: 0.1818\n",
            "Epoch 83/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2986 - accuracy: 0.1788 - val_loss: 0.5464 - val_accuracy: 0.1695\n",
            "Epoch 84/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2869 - accuracy: 0.1790 - val_loss: 0.5177 - val_accuracy: 0.1796\n",
            "Epoch 85/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3003 - accuracy: 0.1779 - val_loss: 0.5901 - val_accuracy: 0.1818\n",
            "Epoch 86/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2835 - accuracy: 0.1815 - val_loss: 0.5028 - val_accuracy: 0.1782\n",
            "Epoch 87/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2727 - accuracy: 0.1812 - val_loss: 0.6544 - val_accuracy: 0.1833\n",
            "Epoch 88/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2970 - accuracy: 0.1796 - val_loss: 0.5174 - val_accuracy: 0.1716\n",
            "Epoch 89/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2742 - accuracy: 0.1811 - val_loss: 0.5688 - val_accuracy: 0.1796\n",
            "Epoch 90/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.2850 - accuracy: 0.1800 - val_loss: 0.6005 - val_accuracy: 0.1695\n",
            "Epoch 91/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2748 - accuracy: 0.1770 - val_loss: 0.5680 - val_accuracy: 0.1818\n",
            "Epoch 92/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2700 - accuracy: 0.1802 - val_loss: 0.5035 - val_accuracy: 0.1775\n",
            "Epoch 93/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2879 - accuracy: 0.1796 - val_loss: 0.4858 - val_accuracy: 0.1716\n",
            "Epoch 94/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2684 - accuracy: 0.1788 - val_loss: 0.5411 - val_accuracy: 0.1833\n",
            "Epoch 95/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.2798 - accuracy: 0.1790 - val_loss: 0.5397 - val_accuracy: 0.1847\n",
            "Epoch 96/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2588 - accuracy: 0.1790 - val_loss: 0.5188 - val_accuracy: 0.1673\n",
            "Epoch 97/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2747 - accuracy: 0.1787 - val_loss: 0.4802 - val_accuracy: 0.1811\n",
            "Epoch 98/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2708 - accuracy: 0.1793 - val_loss: 0.5713 - val_accuracy: 0.1811\n",
            "Epoch 99/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.2597 - accuracy: 0.1804 - val_loss: 0.5764 - val_accuracy: 0.1753\n",
            "Epoch 100/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2659 - accuracy: 0.1786 - val_loss: 0.5041 - val_accuracy: 0.1724\n",
            "Epoch 101/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2652 - accuracy: 0.1793 - val_loss: 0.4849 - val_accuracy: 0.1825\n",
            "Epoch 102/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.2546 - accuracy: 0.1800 - val_loss: 0.5466 - val_accuracy: 0.1825\n",
            "Epoch 103/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.2621 - accuracy: 0.1810 - val_loss: 0.5596 - val_accuracy: 0.1629\n",
            "Epoch 104/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2630 - accuracy: 0.1770 - val_loss: 0.5832 - val_accuracy: 0.1745\n",
            "Epoch 105/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.2572 - accuracy: 0.1802 - val_loss: 0.4795 - val_accuracy: 0.1716\n",
            "Epoch 106/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.2604 - accuracy: 0.1787 - val_loss: 0.4840 - val_accuracy: 0.1847\n",
            "Epoch 107/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.2401 - accuracy: 0.1806 - val_loss: 0.4689 - val_accuracy: 0.1818\n",
            "Epoch 108/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.2494 - accuracy: 0.1800 - val_loss: 0.4864 - val_accuracy: 0.1782\n",
            "Epoch 109/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.2519 - accuracy: 0.1804 - val_loss: 0.5942 - val_accuracy: 0.1782\n",
            "Epoch 110/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2637 - accuracy: 0.1814 - val_loss: 0.4988 - val_accuracy: 0.1724\n",
            "Epoch 111/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2457 - accuracy: 0.1786 - val_loss: 0.4716 - val_accuracy: 0.1862\n",
            "Epoch 112/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.2469 - accuracy: 0.1813 - val_loss: 0.5760 - val_accuracy: 0.1767\n",
            "Epoch 113/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2507 - accuracy: 0.1804 - val_loss: 0.5323 - val_accuracy: 0.1811\n",
            "Epoch 114/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2282 - accuracy: 0.1808 - val_loss: 0.4899 - val_accuracy: 0.1833\n",
            "Epoch 115/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2484 - accuracy: 0.1794 - val_loss: 0.5445 - val_accuracy: 0.1825\n",
            "Epoch 116/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2453 - accuracy: 0.1816 - val_loss: 0.4700 - val_accuracy: 0.1753\n",
            "Epoch 117/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2431 - accuracy: 0.1778 - val_loss: 0.5665 - val_accuracy: 0.1804\n",
            "Epoch 118/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2409 - accuracy: 0.1809 - val_loss: 0.5105 - val_accuracy: 0.1833\n",
            "Epoch 119/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.2386 - accuracy: 0.1797 - val_loss: 0.5045 - val_accuracy: 0.1818\n",
            "Epoch 120/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2225 - accuracy: 0.1814 - val_loss: 0.4688 - val_accuracy: 0.1745\n",
            "Epoch 121/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2193 - accuracy: 0.1800 - val_loss: 0.5860 - val_accuracy: 0.1738\n",
            "Epoch 122/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2418 - accuracy: 0.1789 - val_loss: 0.5280 - val_accuracy: 0.1731\n",
            "Epoch 123/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2207 - accuracy: 0.1779 - val_loss: 0.5096 - val_accuracy: 0.1796\n",
            "Epoch 124/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2349 - accuracy: 0.1792 - val_loss: 0.4877 - val_accuracy: 0.1847\n",
            "Epoch 125/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.2328 - accuracy: 0.1810 - val_loss: 0.4604 - val_accuracy: 0.1753\n",
            "Epoch 126/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2351 - accuracy: 0.1792 - val_loss: 0.4994 - val_accuracy: 0.1855\n",
            "Epoch 127/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2367 - accuracy: 0.1818 - val_loss: 0.4871 - val_accuracy: 0.1767\n",
            "Epoch 128/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2252 - accuracy: 0.1823 - val_loss: 0.5188 - val_accuracy: 0.1825\n",
            "Epoch 129/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.2279 - accuracy: 0.1805 - val_loss: 0.4808 - val_accuracy: 0.1825\n",
            "Epoch 130/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2156 - accuracy: 0.1818 - val_loss: 0.5323 - val_accuracy: 0.1767\n",
            "Epoch 131/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2184 - accuracy: 0.1818 - val_loss: 0.4802 - val_accuracy: 0.1745\n",
            "Epoch 132/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2173 - accuracy: 0.1791 - val_loss: 0.4419 - val_accuracy: 0.1847\n",
            "Epoch 133/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2285 - accuracy: 0.1787 - val_loss: 0.5212 - val_accuracy: 0.1833\n",
            "Epoch 134/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2097 - accuracy: 0.1806 - val_loss: 0.4845 - val_accuracy: 0.1738\n",
            "Epoch 135/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.2106 - accuracy: 0.1803 - val_loss: 0.5254 - val_accuracy: 0.1789\n",
            "Epoch 136/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2193 - accuracy: 0.1815 - val_loss: 0.4974 - val_accuracy: 0.1818\n",
            "Epoch 137/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2173 - accuracy: 0.1822 - val_loss: 0.4578 - val_accuracy: 0.1789\n",
            "Epoch 138/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2128 - accuracy: 0.1816 - val_loss: 0.4468 - val_accuracy: 0.1825\n",
            "Epoch 139/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2169 - accuracy: 0.1813 - val_loss: 0.5628 - val_accuracy: 0.1767\n",
            "Epoch 140/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2243 - accuracy: 0.1801 - val_loss: 0.5041 - val_accuracy: 0.1775\n",
            "Epoch 141/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2071 - accuracy: 0.1810 - val_loss: 0.4395 - val_accuracy: 0.1804\n",
            "Epoch 142/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2111 - accuracy: 0.1820 - val_loss: 0.5571 - val_accuracy: 0.1862\n",
            "Epoch 143/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.2190 - accuracy: 0.1824 - val_loss: 0.4722 - val_accuracy: 0.1840\n",
            "Epoch 144/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2145 - accuracy: 0.1820 - val_loss: 0.4645 - val_accuracy: 0.1782\n",
            "Epoch 145/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2015 - accuracy: 0.1818 - val_loss: 0.4375 - val_accuracy: 0.1840\n",
            "Epoch 146/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2048 - accuracy: 0.1818 - val_loss: 0.5235 - val_accuracy: 0.1847\n",
            "Epoch 147/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2216 - accuracy: 0.1789 - val_loss: 0.4668 - val_accuracy: 0.1753\n",
            "Epoch 148/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1939 - accuracy: 0.1818 - val_loss: 0.5388 - val_accuracy: 0.1760\n",
            "Epoch 149/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2052 - accuracy: 0.1799 - val_loss: 0.5114 - val_accuracy: 0.1782\n",
            "Epoch 150/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1937 - accuracy: 0.1800 - val_loss: 0.4503 - val_accuracy: 0.1804\n",
            "Epoch 151/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.2061 - accuracy: 0.1806 - val_loss: 0.4565 - val_accuracy: 0.1818\n",
            "Epoch 152/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1908 - accuracy: 0.1813 - val_loss: 0.4396 - val_accuracy: 0.1767\n",
            "Epoch 153/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2025 - accuracy: 0.1791 - val_loss: 0.4476 - val_accuracy: 0.1825\n",
            "Epoch 154/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2087 - accuracy: 0.1804 - val_loss: 0.4466 - val_accuracy: 0.1840\n",
            "Epoch 155/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1990 - accuracy: 0.1819 - val_loss: 0.5588 - val_accuracy: 0.1796\n",
            "Epoch 156/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1984 - accuracy: 0.1807 - val_loss: 0.4969 - val_accuracy: 0.1855\n",
            "Epoch 157/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1964 - accuracy: 0.1833 - val_loss: 0.4521 - val_accuracy: 0.1767\n",
            "Epoch 158/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1959 - accuracy: 0.1805 - val_loss: 0.5038 - val_accuracy: 0.1862\n",
            "Epoch 159/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1920 - accuracy: 0.1819 - val_loss: 0.4730 - val_accuracy: 0.1731\n",
            "Epoch 160/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2113 - accuracy: 0.1780 - val_loss: 0.4434 - val_accuracy: 0.1847\n",
            "Epoch 161/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1915 - accuracy: 0.1835 - val_loss: 0.4559 - val_accuracy: 0.1745\n",
            "Epoch 162/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2002 - accuracy: 0.1818 - val_loss: 0.4896 - val_accuracy: 0.1825\n",
            "Epoch 163/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1882 - accuracy: 0.1816 - val_loss: 0.4304 - val_accuracy: 0.1804\n",
            "Epoch 164/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1916 - accuracy: 0.1821 - val_loss: 0.5460 - val_accuracy: 0.1767\n",
            "Epoch 165/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1956 - accuracy: 0.1805 - val_loss: 0.4546 - val_accuracy: 0.1811\n",
            "Epoch 166/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1914 - accuracy: 0.1826 - val_loss: 0.4488 - val_accuracy: 0.1811\n",
            "Epoch 167/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1978 - accuracy: 0.1816 - val_loss: 0.4908 - val_accuracy: 0.1855\n",
            "Epoch 168/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1993 - accuracy: 0.1825 - val_loss: 0.4431 - val_accuracy: 0.1782\n",
            "Epoch 169/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1968 - accuracy: 0.1807 - val_loss: 0.4427 - val_accuracy: 0.1840\n",
            "Epoch 170/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1941 - accuracy: 0.1815 - val_loss: 0.5032 - val_accuracy: 0.1818\n",
            "Epoch 171/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1875 - accuracy: 0.1829 - val_loss: 0.4753 - val_accuracy: 0.1847\n",
            "Epoch 172/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1824 - accuracy: 0.1832 - val_loss: 0.4609 - val_accuracy: 0.1796\n",
            "Epoch 173/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1898 - accuracy: 0.1808 - val_loss: 0.5015 - val_accuracy: 0.1862\n",
            "Epoch 174/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1938 - accuracy: 0.1819 - val_loss: 0.4832 - val_accuracy: 0.1796\n",
            "Epoch 175/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1817 - accuracy: 0.1821 - val_loss: 0.4809 - val_accuracy: 0.1789\n",
            "Epoch 176/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1789 - accuracy: 0.1825 - val_loss: 0.4429 - val_accuracy: 0.1833\n",
            "Epoch 177/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1881 - accuracy: 0.1810 - val_loss: 0.4281 - val_accuracy: 0.1825\n",
            "Epoch 178/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1831 - accuracy: 0.1812 - val_loss: 0.4786 - val_accuracy: 0.1840\n",
            "Epoch 179/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1794 - accuracy: 0.1821 - val_loss: 0.4302 - val_accuracy: 0.1811\n",
            "Epoch 180/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.1672 - accuracy: 0.1816 - val_loss: 0.4744 - val_accuracy: 0.1811\n",
            "Epoch 181/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1677 - accuracy: 0.1836 - val_loss: 0.4352 - val_accuracy: 0.1825\n",
            "Epoch 182/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.1838 - accuracy: 0.1823 - val_loss: 0.4690 - val_accuracy: 0.1869\n",
            "Epoch 183/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1761 - accuracy: 0.1838 - val_loss: 0.4267 - val_accuracy: 0.1840\n",
            "Epoch 184/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1761 - accuracy: 0.1830 - val_loss: 0.4545 - val_accuracy: 0.1855\n",
            "Epoch 185/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1939 - accuracy: 0.1826 - val_loss: 0.4492 - val_accuracy: 0.1753\n",
            "Epoch 186/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1826 - accuracy: 0.1809 - val_loss: 0.4711 - val_accuracy: 0.1855\n",
            "Epoch 187/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1773 - accuracy: 0.1828 - val_loss: 0.4222 - val_accuracy: 0.1804\n",
            "Epoch 188/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1784 - accuracy: 0.1826 - val_loss: 0.5119 - val_accuracy: 0.1789\n",
            "Epoch 189/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1673 - accuracy: 0.1821 - val_loss: 0.4373 - val_accuracy: 0.1833\n",
            "Epoch 190/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1876 - accuracy: 0.1819 - val_loss: 0.4191 - val_accuracy: 0.1855\n",
            "Epoch 191/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1664 - accuracy: 0.1835 - val_loss: 0.4688 - val_accuracy: 0.1862\n",
            "Epoch 192/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1744 - accuracy: 0.1822 - val_loss: 0.4368 - val_accuracy: 0.1825\n",
            "Epoch 193/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1645 - accuracy: 0.1832 - val_loss: 0.4958 - val_accuracy: 0.1789\n",
            "Epoch 194/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1643 - accuracy: 0.1837 - val_loss: 0.4552 - val_accuracy: 0.1818\n",
            "Epoch 195/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1729 - accuracy: 0.1831 - val_loss: 0.4597 - val_accuracy: 0.1847\n",
            "Epoch 196/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1752 - accuracy: 0.1838 - val_loss: 0.4759 - val_accuracy: 0.1825\n",
            "Epoch 197/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1726 - accuracy: 0.1837 - val_loss: 0.4251 - val_accuracy: 0.1789\n",
            "Epoch 198/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1739 - accuracy: 0.1822 - val_loss: 0.4003 - val_accuracy: 0.1855\n",
            "Epoch 199/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1696 - accuracy: 0.1823 - val_loss: 0.4359 - val_accuracy: 0.1847\n",
            "Epoch 200/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1735 - accuracy: 0.1836 - val_loss: 0.4599 - val_accuracy: 0.1876\n",
            "Epoch 201/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1620 - accuracy: 0.1826 - val_loss: 0.4761 - val_accuracy: 0.1804\n",
            "Epoch 202/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1687 - accuracy: 0.1829 - val_loss: 0.4435 - val_accuracy: 0.1833\n",
            "Epoch 203/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1699 - accuracy: 0.1829 - val_loss: 0.4617 - val_accuracy: 0.1869\n",
            "Epoch 204/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1737 - accuracy: 0.1834 - val_loss: 0.4345 - val_accuracy: 0.1804\n",
            "Epoch 205/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1648 - accuracy: 0.1833 - val_loss: 0.4615 - val_accuracy: 0.1811\n",
            "Epoch 206/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1745 - accuracy: 0.1837 - val_loss: 0.4525 - val_accuracy: 0.1876\n",
            "Epoch 207/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1688 - accuracy: 0.1821 - val_loss: 0.4197 - val_accuracy: 0.1833\n",
            "Epoch 208/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1662 - accuracy: 0.1840 - val_loss: 0.4865 - val_accuracy: 0.1789\n",
            "Epoch 209/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1636 - accuracy: 0.1821 - val_loss: 0.4266 - val_accuracy: 0.1796\n",
            "Epoch 210/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1594 - accuracy: 0.1837 - val_loss: 0.4891 - val_accuracy: 0.1833\n",
            "Epoch 211/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1685 - accuracy: 0.1830 - val_loss: 0.4441 - val_accuracy: 0.1840\n",
            "Epoch 212/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1732 - accuracy: 0.1830 - val_loss: 0.4593 - val_accuracy: 0.1869\n",
            "Epoch 213/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1637 - accuracy: 0.1829 - val_loss: 0.4052 - val_accuracy: 0.1833\n",
            "Epoch 214/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1604 - accuracy: 0.1817 - val_loss: 0.4201 - val_accuracy: 0.1840\n",
            "Epoch 215/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1583 - accuracy: 0.1836 - val_loss: 0.4365 - val_accuracy: 0.1862\n",
            "Epoch 216/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1647 - accuracy: 0.1833 - val_loss: 0.4344 - val_accuracy: 0.1862\n",
            "Epoch 217/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1537 - accuracy: 0.1829 - val_loss: 0.4139 - val_accuracy: 0.1818\n",
            "Epoch 218/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1591 - accuracy: 0.1835 - val_loss: 0.4308 - val_accuracy: 0.1789\n",
            "Epoch 219/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1584 - accuracy: 0.1834 - val_loss: 0.4083 - val_accuracy: 0.1862\n",
            "Epoch 220/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1601 - accuracy: 0.1833 - val_loss: 0.4774 - val_accuracy: 0.1825\n",
            "Epoch 221/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1643 - accuracy: 0.1829 - val_loss: 0.4700 - val_accuracy: 0.1847\n",
            "Epoch 222/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1606 - accuracy: 0.1836 - val_loss: 0.4221 - val_accuracy: 0.1862\n",
            "Epoch 223/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1588 - accuracy: 0.1840 - val_loss: 0.4557 - val_accuracy: 0.1847\n",
            "Epoch 224/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1485 - accuracy: 0.1841 - val_loss: 0.4173 - val_accuracy: 0.1847\n",
            "Epoch 225/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1611 - accuracy: 0.1840 - val_loss: 0.4160 - val_accuracy: 0.1862\n",
            "Epoch 226/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1554 - accuracy: 0.1836 - val_loss: 0.4235 - val_accuracy: 0.1840\n",
            "Epoch 227/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1404 - accuracy: 0.1837 - val_loss: 0.4402 - val_accuracy: 0.1840\n",
            "Epoch 228/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1513 - accuracy: 0.1841 - val_loss: 0.4525 - val_accuracy: 0.1811\n",
            "Epoch 229/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1478 - accuracy: 0.1839 - val_loss: 0.4352 - val_accuracy: 0.1825\n",
            "Epoch 230/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1594 - accuracy: 0.1830 - val_loss: 0.4241 - val_accuracy: 0.1869\n",
            "Epoch 231/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1522 - accuracy: 0.1836 - val_loss: 0.4552 - val_accuracy: 0.1855\n",
            "Epoch 232/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1585 - accuracy: 0.1841 - val_loss: 0.4196 - val_accuracy: 0.1847\n",
            "Epoch 233/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1554 - accuracy: 0.1827 - val_loss: 0.3923 - val_accuracy: 0.1840\n",
            "Epoch 234/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1397 - accuracy: 0.1830 - val_loss: 0.4721 - val_accuracy: 0.1789\n",
            "Epoch 235/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1633 - accuracy: 0.1827 - val_loss: 0.4224 - val_accuracy: 0.1840\n",
            "Epoch 236/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1494 - accuracy: 0.1833 - val_loss: 0.4276 - val_accuracy: 0.1876\n",
            "Epoch 237/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1545 - accuracy: 0.1836 - val_loss: 0.4483 - val_accuracy: 0.1767\n",
            "Epoch 238/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1681 - accuracy: 0.1829 - val_loss: 0.4161 - val_accuracy: 0.1855\n",
            "Epoch 239/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1456 - accuracy: 0.1833 - val_loss: 0.4649 - val_accuracy: 0.1862\n",
            "Epoch 240/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1548 - accuracy: 0.1838 - val_loss: 0.4336 - val_accuracy: 0.1825\n",
            "Epoch 241/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1501 - accuracy: 0.1831 - val_loss: 0.4271 - val_accuracy: 0.1876\n",
            "Epoch 242/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1446 - accuracy: 0.1840 - val_loss: 0.4445 - val_accuracy: 0.1847\n",
            "Epoch 243/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1389 - accuracy: 0.1841 - val_loss: 0.4442 - val_accuracy: 0.1782\n",
            "Epoch 244/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1458 - accuracy: 0.1828 - val_loss: 0.4016 - val_accuracy: 0.1811\n",
            "Epoch 245/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1413 - accuracy: 0.1834 - val_loss: 0.4451 - val_accuracy: 0.1818\n",
            "Epoch 246/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1466 - accuracy: 0.1838 - val_loss: 0.4581 - val_accuracy: 0.1876\n",
            "Epoch 247/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1527 - accuracy: 0.1841 - val_loss: 0.4384 - val_accuracy: 0.1840\n",
            "Epoch 248/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1585 - accuracy: 0.1827 - val_loss: 0.4527 - val_accuracy: 0.1869\n",
            "Epoch 249/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1387 - accuracy: 0.1834 - val_loss: 0.4388 - val_accuracy: 0.1855\n",
            "Epoch 250/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1371 - accuracy: 0.1841 - val_loss: 0.4190 - val_accuracy: 0.1804\n",
            "Epoch 251/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1440 - accuracy: 0.1833 - val_loss: 0.4064 - val_accuracy: 0.1840\n",
            "Epoch 252/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1513 - accuracy: 0.1839 - val_loss: 0.4741 - val_accuracy: 0.1869\n",
            "Epoch 253/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1506 - accuracy: 0.1841 - val_loss: 0.4425 - val_accuracy: 0.1833\n",
            "Epoch 254/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1478 - accuracy: 0.1841 - val_loss: 0.4038 - val_accuracy: 0.1855\n",
            "Epoch 255/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1470 - accuracy: 0.1835 - val_loss: 0.4331 - val_accuracy: 0.1833\n",
            "Epoch 256/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1389 - accuracy: 0.1840 - val_loss: 0.4232 - val_accuracy: 0.1825\n",
            "Epoch 257/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1441 - accuracy: 0.1839 - val_loss: 0.3988 - val_accuracy: 0.1876\n",
            "Epoch 258/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1354 - accuracy: 0.1841 - val_loss: 0.4138 - val_accuracy: 0.1855\n",
            "Epoch 259/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1383 - accuracy: 0.1837 - val_loss: 0.4642 - val_accuracy: 0.1869\n",
            "Epoch 260/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1414 - accuracy: 0.1837 - val_loss: 0.4055 - val_accuracy: 0.1840\n",
            "Epoch 261/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1424 - accuracy: 0.1836 - val_loss: 0.4326 - val_accuracy: 0.1840\n",
            "Epoch 262/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1353 - accuracy: 0.1841 - val_loss: 0.4482 - val_accuracy: 0.1840\n",
            "Epoch 263/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1386 - accuracy: 0.1836 - val_loss: 0.4233 - val_accuracy: 0.1869\n",
            "Epoch 264/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1471 - accuracy: 0.1834 - val_loss: 0.4556 - val_accuracy: 0.1840\n",
            "Epoch 265/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1310 - accuracy: 0.1841 - val_loss: 0.4146 - val_accuracy: 0.1840\n",
            "Epoch 266/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1384 - accuracy: 0.1838 - val_loss: 0.4536 - val_accuracy: 0.1825\n",
            "Epoch 267/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1312 - accuracy: 0.1839 - val_loss: 0.4290 - val_accuracy: 0.1862\n",
            "Epoch 268/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1537 - accuracy: 0.1830 - val_loss: 0.4282 - val_accuracy: 0.1796\n",
            "Epoch 269/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1410 - accuracy: 0.1836 - val_loss: 0.4217 - val_accuracy: 0.1825\n",
            "Epoch 270/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1456 - accuracy: 0.1836 - val_loss: 0.4131 - val_accuracy: 0.1876\n",
            "Epoch 271/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1454 - accuracy: 0.1840 - val_loss: 0.4204 - val_accuracy: 0.1825\n",
            "Epoch 272/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1357 - accuracy: 0.1839 - val_loss: 0.4299 - val_accuracy: 0.1855\n",
            "Epoch 273/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1342 - accuracy: 0.1837 - val_loss: 0.4494 - val_accuracy: 0.1818\n",
            "Epoch 274/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1279 - accuracy: 0.1836 - val_loss: 0.4010 - val_accuracy: 0.1833\n",
            "Epoch 275/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1309 - accuracy: 0.1825 - val_loss: 0.4121 - val_accuracy: 0.1855\n",
            "Epoch 276/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1461 - accuracy: 0.1825 - val_loss: 0.4277 - val_accuracy: 0.1818\n",
            "Epoch 277/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1358 - accuracy: 0.1839 - val_loss: 0.4042 - val_accuracy: 0.1855\n",
            "Epoch 278/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1355 - accuracy: 0.1840 - val_loss: 0.4267 - val_accuracy: 0.1840\n",
            "Epoch 279/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1322 - accuracy: 0.1835 - val_loss: 0.4150 - val_accuracy: 0.1847\n",
            "Epoch 280/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1381 - accuracy: 0.1840 - val_loss: 0.4488 - val_accuracy: 0.1862\n",
            "Epoch 281/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1352 - accuracy: 0.1840 - val_loss: 0.4057 - val_accuracy: 0.1825\n",
            "Epoch 282/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1361 - accuracy: 0.1832 - val_loss: 0.4139 - val_accuracy: 0.1869\n",
            "Epoch 283/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1361 - accuracy: 0.1836 - val_loss: 0.4361 - val_accuracy: 0.1876\n",
            "Epoch 284/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1347 - accuracy: 0.1840 - val_loss: 0.4147 - val_accuracy: 0.1840\n",
            "Epoch 285/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1432 - accuracy: 0.1829 - val_loss: 0.4404 - val_accuracy: 0.1847\n",
            "Epoch 286/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1301 - accuracy: 0.1841 - val_loss: 0.4278 - val_accuracy: 0.1876\n",
            "Epoch 287/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1314 - accuracy: 0.1839 - val_loss: 0.4271 - val_accuracy: 0.1825\n",
            "Epoch 288/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1398 - accuracy: 0.1841 - val_loss: 0.4018 - val_accuracy: 0.1869\n",
            "Epoch 289/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1284 - accuracy: 0.1841 - val_loss: 0.4216 - val_accuracy: 0.1862\n",
            "Epoch 290/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1364 - accuracy: 0.1841 - val_loss: 0.3938 - val_accuracy: 0.1847\n",
            "Epoch 291/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1325 - accuracy: 0.1841 - val_loss: 0.4094 - val_accuracy: 0.1869\n",
            "Epoch 292/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1331 - accuracy: 0.1841 - val_loss: 0.4561 - val_accuracy: 0.1855\n",
            "Epoch 293/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1327 - accuracy: 0.1837 - val_loss: 0.3985 - val_accuracy: 0.1840\n",
            "Epoch 294/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1214 - accuracy: 0.1840 - val_loss: 0.4470 - val_accuracy: 0.1884\n",
            "Epoch 295/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1392 - accuracy: 0.1841 - val_loss: 0.4103 - val_accuracy: 0.1847\n",
            "Epoch 296/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1255 - accuracy: 0.1839 - val_loss: 0.3961 - val_accuracy: 0.1876\n",
            "Epoch 297/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1295 - accuracy: 0.1828 - val_loss: 0.3945 - val_accuracy: 0.1862\n",
            "Epoch 298/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1248 - accuracy: 0.1841 - val_loss: 0.4205 - val_accuracy: 0.1869\n",
            "Epoch 299/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1342 - accuracy: 0.1838 - val_loss: 0.3973 - val_accuracy: 0.1855\n",
            "Epoch 300/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1365 - accuracy: 0.1832 - val_loss: 0.4190 - val_accuracy: 0.1833\n",
            "Epoch 301/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1382 - accuracy: 0.1831 - val_loss: 0.4349 - val_accuracy: 0.1876\n",
            "Epoch 302/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1240 - accuracy: 0.1836 - val_loss: 0.3964 - val_accuracy: 0.1869\n",
            "Epoch 303/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1235 - accuracy: 0.1838 - val_loss: 0.4049 - val_accuracy: 0.1869\n",
            "Epoch 304/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1214 - accuracy: 0.1840 - val_loss: 0.4182 - val_accuracy: 0.1847\n",
            "Epoch 305/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1250 - accuracy: 0.1828 - val_loss: 0.4231 - val_accuracy: 0.1862\n",
            "Epoch 306/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1298 - accuracy: 0.1841 - val_loss: 0.3967 - val_accuracy: 0.1796\n",
            "Epoch 307/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1255 - accuracy: 0.1819 - val_loss: 0.4341 - val_accuracy: 0.1833\n",
            "Epoch 308/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1258 - accuracy: 0.1841 - val_loss: 0.4169 - val_accuracy: 0.1876\n",
            "Epoch 309/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1307 - accuracy: 0.1840 - val_loss: 0.4120 - val_accuracy: 0.1840\n",
            "Epoch 310/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1275 - accuracy: 0.1829 - val_loss: 0.3865 - val_accuracy: 0.1869\n",
            "Epoch 311/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1318 - accuracy: 0.1841 - val_loss: 0.3966 - val_accuracy: 0.1855\n",
            "Epoch 312/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1206 - accuracy: 0.1837 - val_loss: 0.4307 - val_accuracy: 0.1840\n",
            "Epoch 313/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1246 - accuracy: 0.1840 - val_loss: 0.4253 - val_accuracy: 0.1862\n",
            "Epoch 314/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1312 - accuracy: 0.1837 - val_loss: 0.4135 - val_accuracy: 0.1862\n",
            "Epoch 315/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1142 - accuracy: 0.1839 - val_loss: 0.3934 - val_accuracy: 0.1840\n",
            "Epoch 316/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1257 - accuracy: 0.1841 - val_loss: 0.4109 - val_accuracy: 0.1876\n",
            "Epoch 317/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1216 - accuracy: 0.1840 - val_loss: 0.3914 - val_accuracy: 0.1847\n",
            "Epoch 318/1000\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.1271 - accuracy: 0.1835 - val_loss: 0.3902 - val_accuracy: 0.1855\n",
            "Epoch 319/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1180 - accuracy: 0.1839 - val_loss: 0.4071 - val_accuracy: 0.1876\n",
            "Epoch 320/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1306 - accuracy: 0.1841 - val_loss: 0.4218 - val_accuracy: 0.1869\n",
            "Epoch 321/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1207 - accuracy: 0.1837 - val_loss: 0.4014 - val_accuracy: 0.1847\n",
            "Epoch 322/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1267 - accuracy: 0.1840 - val_loss: 0.4164 - val_accuracy: 0.1862\n",
            "Epoch 323/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1139 - accuracy: 0.1838 - val_loss: 0.3926 - val_accuracy: 0.1847\n",
            "Epoch 324/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1236 - accuracy: 0.1838 - val_loss: 0.3980 - val_accuracy: 0.1876\n",
            "Epoch 325/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1197 - accuracy: 0.1841 - val_loss: 0.3991 - val_accuracy: 0.1855\n",
            "Epoch 326/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1229 - accuracy: 0.1839 - val_loss: 0.4221 - val_accuracy: 0.1876\n",
            "Epoch 327/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1235 - accuracy: 0.1840 - val_loss: 0.4046 - val_accuracy: 0.1847\n",
            "Epoch 328/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1239 - accuracy: 0.1834 - val_loss: 0.4270 - val_accuracy: 0.1876\n",
            "Epoch 329/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1228 - accuracy: 0.1841 - val_loss: 0.4052 - val_accuracy: 0.1840\n",
            "Epoch 330/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1213 - accuracy: 0.1830 - val_loss: 0.4106 - val_accuracy: 0.1840\n",
            "Epoch 331/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.1104 - accuracy: 0.1841 - val_loss: 0.4192 - val_accuracy: 0.1876\n",
            "Epoch 332/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1174 - accuracy: 0.1840 - val_loss: 0.3987 - val_accuracy: 0.1855\n",
            "Epoch 333/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1216 - accuracy: 0.1841 - val_loss: 0.3863 - val_accuracy: 0.1862\n",
            "Epoch 334/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1138 - accuracy: 0.1841 - val_loss: 0.4061 - val_accuracy: 0.1869\n",
            "Epoch 335/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1228 - accuracy: 0.1839 - val_loss: 0.4152 - val_accuracy: 0.1855\n",
            "Epoch 336/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1141 - accuracy: 0.1841 - val_loss: 0.3904 - val_accuracy: 0.1847\n",
            "Epoch 337/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1146 - accuracy: 0.1837 - val_loss: 0.3952 - val_accuracy: 0.1869\n",
            "Epoch 338/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1252 - accuracy: 0.1841 - val_loss: 0.3994 - val_accuracy: 0.1876\n",
            "Epoch 339/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1134 - accuracy: 0.1837 - val_loss: 0.4009 - val_accuracy: 0.1869\n",
            "Epoch 340/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1186 - accuracy: 0.1839 - val_loss: 0.4114 - val_accuracy: 0.1862\n",
            "Epoch 341/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1218 - accuracy: 0.1840 - val_loss: 0.4139 - val_accuracy: 0.1862\n",
            "Epoch 342/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1178 - accuracy: 0.1835 - val_loss: 0.4100 - val_accuracy: 0.1804\n",
            "Epoch 343/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1091 - accuracy: 0.1839 - val_loss: 0.3935 - val_accuracy: 0.1862\n",
            "Epoch 344/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1130 - accuracy: 0.1840 - val_loss: 0.3892 - val_accuracy: 0.1876\n",
            "Epoch 345/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1133 - accuracy: 0.1834 - val_loss: 0.4061 - val_accuracy: 0.1847\n",
            "Epoch 346/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1219 - accuracy: 0.1837 - val_loss: 0.3991 - val_accuracy: 0.1884\n",
            "Epoch 347/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1154 - accuracy: 0.1840 - val_loss: 0.3890 - val_accuracy: 0.1862\n",
            "Epoch 348/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1220 - accuracy: 0.1841 - val_loss: 0.3990 - val_accuracy: 0.1876\n",
            "Epoch 349/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1203 - accuracy: 0.1839 - val_loss: 0.4307 - val_accuracy: 0.1876\n",
            "Epoch 350/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1095 - accuracy: 0.1840 - val_loss: 0.3867 - val_accuracy: 0.1869\n",
            "Epoch 351/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1175 - accuracy: 0.1841 - val_loss: 0.4085 - val_accuracy: 0.1876\n",
            "Epoch 352/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1134 - accuracy: 0.1841 - val_loss: 0.3813 - val_accuracy: 0.1862\n",
            "Epoch 353/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.1097 - accuracy: 0.1841 - val_loss: 0.3994 - val_accuracy: 0.1876\n",
            "Epoch 354/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1218 - accuracy: 0.1837 - val_loss: 0.3876 - val_accuracy: 0.1862\n",
            "Epoch 355/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1196 - accuracy: 0.1841 - val_loss: 0.3978 - val_accuracy: 0.1855\n",
            "Epoch 356/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1100 - accuracy: 0.1841 - val_loss: 0.3936 - val_accuracy: 0.1869\n",
            "Epoch 357/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1200 - accuracy: 0.1841 - val_loss: 0.4080 - val_accuracy: 0.1833\n",
            "Epoch 358/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.1065 - accuracy: 0.1841 - val_loss: 0.4005 - val_accuracy: 0.1876\n",
            "Epoch 359/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.1096 - accuracy: 0.1841 - val_loss: 0.4086 - val_accuracy: 0.1847\n",
            "Epoch 360/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1167 - accuracy: 0.1823 - val_loss: 0.4072 - val_accuracy: 0.1884\n",
            "Epoch 361/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1130 - accuracy: 0.1841 - val_loss: 0.3976 - val_accuracy: 0.1847\n",
            "Epoch 362/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.1101 - accuracy: 0.1837 - val_loss: 0.4353 - val_accuracy: 0.1876\n",
            "Epoch 363/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1158 - accuracy: 0.1840 - val_loss: 0.3950 - val_accuracy: 0.1884\n",
            "Epoch 364/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1118 - accuracy: 0.1836 - val_loss: 0.3782 - val_accuracy: 0.1876\n",
            "Epoch 365/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1096 - accuracy: 0.1831 - val_loss: 0.3927 - val_accuracy: 0.1869\n",
            "Epoch 366/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1174 - accuracy: 0.1841 - val_loss: 0.4226 - val_accuracy: 0.1876\n",
            "Epoch 367/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1174 - accuracy: 0.1841 - val_loss: 0.3860 - val_accuracy: 0.1884\n",
            "Epoch 368/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0940 - accuracy: 0.1841 - val_loss: 0.3808 - val_accuracy: 0.1847\n",
            "Epoch 369/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1178 - accuracy: 0.1836 - val_loss: 0.4151 - val_accuracy: 0.1862\n",
            "Epoch 370/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1064 - accuracy: 0.1841 - val_loss: 0.3928 - val_accuracy: 0.1876\n",
            "Epoch 371/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1053 - accuracy: 0.1835 - val_loss: 0.3941 - val_accuracy: 0.1855\n",
            "Epoch 372/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.1145 - accuracy: 0.1841 - val_loss: 0.3966 - val_accuracy: 0.1876\n",
            "Epoch 373/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1078 - accuracy: 0.1840 - val_loss: 0.3980 - val_accuracy: 0.1869\n",
            "Epoch 374/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1038 - accuracy: 0.1840 - val_loss: 0.3961 - val_accuracy: 0.1862\n",
            "Epoch 375/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1066 - accuracy: 0.1838 - val_loss: 0.3987 - val_accuracy: 0.1855\n",
            "Epoch 376/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1124 - accuracy: 0.1839 - val_loss: 0.4023 - val_accuracy: 0.1884\n",
            "Epoch 377/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1093 - accuracy: 0.1841 - val_loss: 0.4034 - val_accuracy: 0.1847\n",
            "Epoch 378/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1097 - accuracy: 0.1832 - val_loss: 0.3984 - val_accuracy: 0.1884\n",
            "Epoch 379/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.1094 - accuracy: 0.1841 - val_loss: 0.4062 - val_accuracy: 0.1840\n",
            "Epoch 380/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1150 - accuracy: 0.1841 - val_loss: 0.4211 - val_accuracy: 0.1884\n",
            "Epoch 381/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1120 - accuracy: 0.1841 - val_loss: 0.4157 - val_accuracy: 0.1869\n",
            "Epoch 382/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1022 - accuracy: 0.1841 - val_loss: 0.4127 - val_accuracy: 0.1855\n",
            "Epoch 383/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1111 - accuracy: 0.1841 - val_loss: 0.3770 - val_accuracy: 0.1884\n",
            "Epoch 384/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1048 - accuracy: 0.1841 - val_loss: 0.3976 - val_accuracy: 0.1876\n",
            "Epoch 385/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1120 - accuracy: 0.1841 - val_loss: 0.3903 - val_accuracy: 0.1855\n",
            "Epoch 386/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0995 - accuracy: 0.1841 - val_loss: 0.3768 - val_accuracy: 0.1869\n",
            "Epoch 387/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1168 - accuracy: 0.1837 - val_loss: 0.4007 - val_accuracy: 0.1884\n",
            "Epoch 388/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1060 - accuracy: 0.1841 - val_loss: 0.3867 - val_accuracy: 0.1876\n",
            "Epoch 389/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1029 - accuracy: 0.1841 - val_loss: 0.4205 - val_accuracy: 0.1884\n",
            "Epoch 390/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1032 - accuracy: 0.1836 - val_loss: 0.3893 - val_accuracy: 0.1855\n",
            "Epoch 391/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1048 - accuracy: 0.1841 - val_loss: 0.4077 - val_accuracy: 0.1884\n",
            "Epoch 392/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1047 - accuracy: 0.1841 - val_loss: 0.3955 - val_accuracy: 0.1876\n",
            "Epoch 393/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1081 - accuracy: 0.1839 - val_loss: 0.3844 - val_accuracy: 0.1862\n",
            "Epoch 394/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0980 - accuracy: 0.1829 - val_loss: 0.3863 - val_accuracy: 0.1862\n",
            "Epoch 395/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1079 - accuracy: 0.1836 - val_loss: 0.3859 - val_accuracy: 0.1884\n",
            "Epoch 396/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1041 - accuracy: 0.1841 - val_loss: 0.3745 - val_accuracy: 0.1876\n",
            "Epoch 397/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1030 - accuracy: 0.1840 - val_loss: 0.3928 - val_accuracy: 0.1876\n",
            "Epoch 398/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1025 - accuracy: 0.1841 - val_loss: 0.3875 - val_accuracy: 0.1869\n",
            "Epoch 399/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1042 - accuracy: 0.1841 - val_loss: 0.3904 - val_accuracy: 0.1869\n",
            "Epoch 400/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1067 - accuracy: 0.1841 - val_loss: 0.3991 - val_accuracy: 0.1847\n",
            "Epoch 401/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1033 - accuracy: 0.1841 - val_loss: 0.4021 - val_accuracy: 0.1884\n",
            "Epoch 402/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0984 - accuracy: 0.1839 - val_loss: 0.3985 - val_accuracy: 0.1869\n",
            "Epoch 403/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.1134 - accuracy: 0.1839 - val_loss: 0.4070 - val_accuracy: 0.1876\n",
            "Epoch 404/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1033 - accuracy: 0.1835 - val_loss: 0.3857 - val_accuracy: 0.1855\n",
            "Epoch 405/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1049 - accuracy: 0.1841 - val_loss: 0.4024 - val_accuracy: 0.1884\n",
            "Epoch 406/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1018 - accuracy: 0.1841 - val_loss: 0.4003 - val_accuracy: 0.1869\n",
            "Epoch 407/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1112 - accuracy: 0.1839 - val_loss: 0.3948 - val_accuracy: 0.1869\n",
            "Epoch 408/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1027 - accuracy: 0.1841 - val_loss: 0.3754 - val_accuracy: 0.1884\n",
            "Epoch 409/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1039 - accuracy: 0.1841 - val_loss: 0.4028 - val_accuracy: 0.1862\n",
            "Epoch 410/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0991 - accuracy: 0.1841 - val_loss: 0.3771 - val_accuracy: 0.1869\n",
            "Epoch 411/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1081 - accuracy: 0.1841 - val_loss: 0.3855 - val_accuracy: 0.1884\n",
            "Epoch 412/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0962 - accuracy: 0.1841 - val_loss: 0.3914 - val_accuracy: 0.1884\n",
            "Epoch 413/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0998 - accuracy: 0.1841 - val_loss: 0.3853 - val_accuracy: 0.1869\n",
            "Epoch 414/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0992 - accuracy: 0.1841 - val_loss: 0.3959 - val_accuracy: 0.1884\n",
            "Epoch 415/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1005 - accuracy: 0.1839 - val_loss: 0.3898 - val_accuracy: 0.1862\n",
            "Epoch 416/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.1064 - accuracy: 0.1835 - val_loss: 0.3752 - val_accuracy: 0.1884\n",
            "Epoch 417/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0961 - accuracy: 0.1841 - val_loss: 0.3946 - val_accuracy: 0.1876\n",
            "Epoch 418/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1016 - accuracy: 0.1841 - val_loss: 0.4008 - val_accuracy: 0.1862\n",
            "Epoch 419/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1048 - accuracy: 0.1839 - val_loss: 0.3868 - val_accuracy: 0.1876\n",
            "Epoch 420/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.1039 - accuracy: 0.1841 - val_loss: 0.4121 - val_accuracy: 0.1884\n",
            "Epoch 421/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1028 - accuracy: 0.1841 - val_loss: 0.3952 - val_accuracy: 0.1884\n",
            "Epoch 422/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.1028 - accuracy: 0.1841 - val_loss: 0.4031 - val_accuracy: 0.1869\n",
            "Epoch 423/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1077 - accuracy: 0.1841 - val_loss: 0.3789 - val_accuracy: 0.1884\n",
            "Epoch 424/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0959 - accuracy: 0.1841 - val_loss: 0.3811 - val_accuracy: 0.1855\n",
            "Epoch 425/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0957 - accuracy: 0.1839 - val_loss: 0.4066 - val_accuracy: 0.1884\n",
            "Epoch 426/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1018 - accuracy: 0.1841 - val_loss: 0.4011 - val_accuracy: 0.1876\n",
            "Epoch 427/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0952 - accuracy: 0.1840 - val_loss: 0.3840 - val_accuracy: 0.1884\n",
            "Epoch 428/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.1023 - accuracy: 0.1839 - val_loss: 0.3945 - val_accuracy: 0.1876\n",
            "Epoch 429/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0924 - accuracy: 0.1841 - val_loss: 0.3784 - val_accuracy: 0.1876\n",
            "Epoch 430/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1004 - accuracy: 0.1829 - val_loss: 0.3844 - val_accuracy: 0.1884\n",
            "Epoch 431/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0980 - accuracy: 0.1841 - val_loss: 0.3780 - val_accuracy: 0.1884\n",
            "Epoch 432/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0977 - accuracy: 0.1841 - val_loss: 0.3857 - val_accuracy: 0.1876\n",
            "Epoch 433/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0955 - accuracy: 0.1841 - val_loss: 0.3902 - val_accuracy: 0.1869\n",
            "Epoch 434/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0976 - accuracy: 0.1839 - val_loss: 0.3741 - val_accuracy: 0.1876\n",
            "Epoch 435/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0972 - accuracy: 0.1832 - val_loss: 0.3825 - val_accuracy: 0.1876\n",
            "Epoch 436/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1073 - accuracy: 0.1841 - val_loss: 0.3872 - val_accuracy: 0.1876\n",
            "Epoch 437/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0944 - accuracy: 0.1841 - val_loss: 0.3723 - val_accuracy: 0.1884\n",
            "Epoch 438/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0919 - accuracy: 0.1841 - val_loss: 0.3978 - val_accuracy: 0.1876\n",
            "Epoch 439/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0934 - accuracy: 0.1841 - val_loss: 0.3687 - val_accuracy: 0.1884\n",
            "Epoch 440/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0967 - accuracy: 0.1835 - val_loss: 0.3794 - val_accuracy: 0.1884\n",
            "Epoch 441/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0954 - accuracy: 0.1841 - val_loss: 0.3942 - val_accuracy: 0.1884\n",
            "Epoch 442/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0938 - accuracy: 0.1841 - val_loss: 0.3901 - val_accuracy: 0.1869\n",
            "Epoch 443/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1025 - accuracy: 0.1841 - val_loss: 0.3989 - val_accuracy: 0.1884\n",
            "Epoch 444/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0960 - accuracy: 0.1841 - val_loss: 0.3793 - val_accuracy: 0.1884\n",
            "Epoch 445/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0953 - accuracy: 0.1841 - val_loss: 0.3788 - val_accuracy: 0.1876\n",
            "Epoch 446/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0992 - accuracy: 0.1841 - val_loss: 0.3746 - val_accuracy: 0.1876\n",
            "Epoch 447/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0958 - accuracy: 0.1840 - val_loss: 0.4089 - val_accuracy: 0.1884\n",
            "Epoch 448/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0938 - accuracy: 0.1841 - val_loss: 0.3825 - val_accuracy: 0.1869\n",
            "Epoch 449/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0981 - accuracy: 0.1839 - val_loss: 0.3801 - val_accuracy: 0.1884\n",
            "Epoch 450/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0989 - accuracy: 0.1841 - val_loss: 0.3739 - val_accuracy: 0.1884\n",
            "Epoch 451/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0968 - accuracy: 0.1841 - val_loss: 0.3971 - val_accuracy: 0.1884\n",
            "Epoch 452/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1013 - accuracy: 0.1840 - val_loss: 0.3772 - val_accuracy: 0.1876\n",
            "Epoch 453/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0958 - accuracy: 0.1841 - val_loss: 0.3867 - val_accuracy: 0.1884\n",
            "Epoch 454/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0918 - accuracy: 0.1839 - val_loss: 0.3809 - val_accuracy: 0.1862\n",
            "Epoch 455/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0952 - accuracy: 0.1841 - val_loss: 0.3768 - val_accuracy: 0.1884\n",
            "Epoch 456/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1060 - accuracy: 0.1841 - val_loss: 0.3947 - val_accuracy: 0.1876\n",
            "Epoch 457/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1048 - accuracy: 0.1841 - val_loss: 0.3885 - val_accuracy: 0.1884\n",
            "Epoch 458/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0972 - accuracy: 0.1841 - val_loss: 0.3777 - val_accuracy: 0.1884\n",
            "Epoch 459/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0893 - accuracy: 0.1841 - val_loss: 0.3872 - val_accuracy: 0.1876\n",
            "Epoch 460/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0967 - accuracy: 0.1841 - val_loss: 0.4002 - val_accuracy: 0.1869\n",
            "Epoch 461/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1003 - accuracy: 0.1841 - val_loss: 0.3891 - val_accuracy: 0.1884\n",
            "Epoch 462/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0938 - accuracy: 0.1841 - val_loss: 0.3810 - val_accuracy: 0.1884\n",
            "Epoch 463/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0966 - accuracy: 0.1841 - val_loss: 0.3899 - val_accuracy: 0.1884\n",
            "Epoch 464/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.1020 - accuracy: 0.1841 - val_loss: 0.3834 - val_accuracy: 0.1876\n",
            "Epoch 465/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0952 - accuracy: 0.1841 - val_loss: 0.4021 - val_accuracy: 0.1884\n",
            "Epoch 466/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0944 - accuracy: 0.1837 - val_loss: 0.3790 - val_accuracy: 0.1884\n",
            "Epoch 467/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0923 - accuracy: 0.1841 - val_loss: 0.3848 - val_accuracy: 0.1884\n",
            "Epoch 468/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0896 - accuracy: 0.1841 - val_loss: 0.3848 - val_accuracy: 0.1884\n",
            "Epoch 469/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0932 - accuracy: 0.1841 - val_loss: 0.3923 - val_accuracy: 0.1884\n",
            "Epoch 470/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0869 - accuracy: 0.1841 - val_loss: 0.3801 - val_accuracy: 0.1876\n",
            "Epoch 471/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0929 - accuracy: 0.1841 - val_loss: 0.4017 - val_accuracy: 0.1884\n",
            "Epoch 472/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0928 - accuracy: 0.1841 - val_loss: 0.3765 - val_accuracy: 0.1884\n",
            "Epoch 473/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0936 - accuracy: 0.1841 - val_loss: 0.3809 - val_accuracy: 0.1876\n",
            "Epoch 474/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0994 - accuracy: 0.1841 - val_loss: 0.3916 - val_accuracy: 0.1884\n",
            "Epoch 475/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0894 - accuracy: 0.1841 - val_loss: 0.3823 - val_accuracy: 0.1884\n",
            "Epoch 476/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.1007 - accuracy: 0.1841 - val_loss: 0.3863 - val_accuracy: 0.1884\n",
            "Epoch 477/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0935 - accuracy: 0.1841 - val_loss: 0.3710 - val_accuracy: 0.1876\n",
            "Epoch 478/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0949 - accuracy: 0.1832 - val_loss: 0.3837 - val_accuracy: 0.1884\n",
            "Epoch 479/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0913 - accuracy: 0.1841 - val_loss: 0.3974 - val_accuracy: 0.1884\n",
            "Epoch 480/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0977 - accuracy: 0.1841 - val_loss: 0.3763 - val_accuracy: 0.1884\n",
            "Epoch 481/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0917 - accuracy: 0.1841 - val_loss: 0.3879 - val_accuracy: 0.1869\n",
            "Epoch 482/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0940 - accuracy: 0.1841 - val_loss: 0.3824 - val_accuracy: 0.1884\n",
            "Epoch 483/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0963 - accuracy: 0.1841 - val_loss: 0.3780 - val_accuracy: 0.1876\n",
            "Epoch 484/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0920 - accuracy: 0.1841 - val_loss: 0.3733 - val_accuracy: 0.1876\n",
            "Epoch 485/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0880 - accuracy: 0.1841 - val_loss: 0.3954 - val_accuracy: 0.1884\n",
            "Epoch 486/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0960 - accuracy: 0.1841 - val_loss: 0.3748 - val_accuracy: 0.1876\n",
            "Epoch 487/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0939 - accuracy: 0.1841 - val_loss: 0.3751 - val_accuracy: 0.1876\n",
            "Epoch 488/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0868 - accuracy: 0.1841 - val_loss: 0.3812 - val_accuracy: 0.1876\n",
            "Epoch 489/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0976 - accuracy: 0.1841 - val_loss: 0.3829 - val_accuracy: 0.1884\n",
            "Epoch 490/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0928 - accuracy: 0.1839 - val_loss: 0.3709 - val_accuracy: 0.1884\n",
            "Epoch 491/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0924 - accuracy: 0.1841 - val_loss: 0.3870 - val_accuracy: 0.1884\n",
            "Epoch 492/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0846 - accuracy: 0.1841 - val_loss: 0.3763 - val_accuracy: 0.1884\n",
            "Epoch 493/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0925 - accuracy: 0.1841 - val_loss: 0.3852 - val_accuracy: 0.1884\n",
            "Epoch 494/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0921 - accuracy: 0.1841 - val_loss: 0.3820 - val_accuracy: 0.1884\n",
            "Epoch 495/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0934 - accuracy: 0.1835 - val_loss: 0.3831 - val_accuracy: 0.1884\n",
            "Epoch 496/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0895 - accuracy: 0.1835 - val_loss: 0.4041 - val_accuracy: 0.1884\n",
            "Epoch 497/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0911 - accuracy: 0.1841 - val_loss: 0.3834 - val_accuracy: 0.1876\n",
            "Epoch 498/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0925 - accuracy: 0.1841 - val_loss: 0.3761 - val_accuracy: 0.1884\n",
            "Epoch 499/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0924 - accuracy: 0.1841 - val_loss: 0.3808 - val_accuracy: 0.1876\n",
            "Epoch 500/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0935 - accuracy: 0.1841 - val_loss: 0.3817 - val_accuracy: 0.1884\n",
            "Epoch 501/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0823 - accuracy: 0.1841 - val_loss: 0.3804 - val_accuracy: 0.1884\n",
            "Epoch 502/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0890 - accuracy: 0.1841 - val_loss: 0.3837 - val_accuracy: 0.1884\n",
            "Epoch 503/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0853 - accuracy: 0.1841 - val_loss: 0.3626 - val_accuracy: 0.1884\n",
            "Epoch 504/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0838 - accuracy: 0.1841 - val_loss: 0.3778 - val_accuracy: 0.1884\n",
            "Epoch 505/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0878 - accuracy: 0.1841 - val_loss: 0.3657 - val_accuracy: 0.1884\n",
            "Epoch 506/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0839 - accuracy: 0.1841 - val_loss: 0.3738 - val_accuracy: 0.1884\n",
            "Epoch 507/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0900 - accuracy: 0.1841 - val_loss: 0.3723 - val_accuracy: 0.1884\n",
            "Epoch 508/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0930 - accuracy: 0.1841 - val_loss: 0.3827 - val_accuracy: 0.1884\n",
            "Epoch 509/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0897 - accuracy: 0.1841 - val_loss: 0.3720 - val_accuracy: 0.1884\n",
            "Epoch 510/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0822 - accuracy: 0.1841 - val_loss: 0.3760 - val_accuracy: 0.1884\n",
            "Epoch 511/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0857 - accuracy: 0.1841 - val_loss: 0.3730 - val_accuracy: 0.1884\n",
            "Epoch 512/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0886 - accuracy: 0.1841 - val_loss: 0.3775 - val_accuracy: 0.1884\n",
            "Epoch 513/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0859 - accuracy: 0.1841 - val_loss: 0.3909 - val_accuracy: 0.1884\n",
            "Epoch 514/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0931 - accuracy: 0.1841 - val_loss: 0.3836 - val_accuracy: 0.1884\n",
            "Epoch 515/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0865 - accuracy: 0.1841 - val_loss: 0.3891 - val_accuracy: 0.1884\n",
            "Epoch 516/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0950 - accuracy: 0.1841 - val_loss: 0.3836 - val_accuracy: 0.1884\n",
            "Epoch 517/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0832 - accuracy: 0.1841 - val_loss: 0.3755 - val_accuracy: 0.1884\n",
            "Epoch 518/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0986 - accuracy: 0.1839 - val_loss: 0.3741 - val_accuracy: 0.1884\n",
            "Epoch 519/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0885 - accuracy: 0.1835 - val_loss: 0.3784 - val_accuracy: 0.1884\n",
            "Epoch 520/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0874 - accuracy: 0.1841 - val_loss: 0.3679 - val_accuracy: 0.1884\n",
            "Epoch 521/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0843 - accuracy: 0.1839 - val_loss: 0.3706 - val_accuracy: 0.1884\n",
            "Epoch 522/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0852 - accuracy: 0.1841 - val_loss: 0.3841 - val_accuracy: 0.1884\n",
            "Epoch 523/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0849 - accuracy: 0.1841 - val_loss: 0.3649 - val_accuracy: 0.1884\n",
            "Epoch 524/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0835 - accuracy: 0.1841 - val_loss: 0.3835 - val_accuracy: 0.1884\n",
            "Epoch 525/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0944 - accuracy: 0.1841 - val_loss: 0.3775 - val_accuracy: 0.1884\n",
            "Epoch 526/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0874 - accuracy: 0.1832 - val_loss: 0.3856 - val_accuracy: 0.1884\n",
            "Epoch 527/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0821 - accuracy: 0.1839 - val_loss: 0.3603 - val_accuracy: 0.1884\n",
            "Epoch 528/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0866 - accuracy: 0.1840 - val_loss: 0.3741 - val_accuracy: 0.1884\n",
            "Epoch 529/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0884 - accuracy: 0.1841 - val_loss: 0.3906 - val_accuracy: 0.1884\n",
            "Epoch 530/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0797 - accuracy: 0.1841 - val_loss: 0.3735 - val_accuracy: 0.1884\n",
            "Epoch 531/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0852 - accuracy: 0.1841 - val_loss: 0.3774 - val_accuracy: 0.1884\n",
            "Epoch 532/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0894 - accuracy: 0.1841 - val_loss: 0.3700 - val_accuracy: 0.1884\n",
            "Epoch 533/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0878 - accuracy: 0.1841 - val_loss: 0.3870 - val_accuracy: 0.1884\n",
            "Epoch 534/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0796 - accuracy: 0.1839 - val_loss: 0.3754 - val_accuracy: 0.1884\n",
            "Epoch 535/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0839 - accuracy: 0.1841 - val_loss: 0.3846 - val_accuracy: 0.1884\n",
            "Epoch 536/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0808 - accuracy: 0.1841 - val_loss: 0.3722 - val_accuracy: 0.1884\n",
            "Epoch 537/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0851 - accuracy: 0.1841 - val_loss: 0.3742 - val_accuracy: 0.1884\n",
            "Epoch 538/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0844 - accuracy: 0.1841 - val_loss: 0.3736 - val_accuracy: 0.1884\n",
            "Epoch 539/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0830 - accuracy: 0.1841 - val_loss: 0.3739 - val_accuracy: 0.1884\n",
            "Epoch 540/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0849 - accuracy: 0.1841 - val_loss: 0.4053 - val_accuracy: 0.1876\n",
            "Epoch 541/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0834 - accuracy: 0.1841 - val_loss: 0.3763 - val_accuracy: 0.1884\n",
            "Epoch 542/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0798 - accuracy: 0.1841 - val_loss: 0.3644 - val_accuracy: 0.1884\n",
            "Epoch 543/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0843 - accuracy: 0.1841 - val_loss: 0.3756 - val_accuracy: 0.1884\n",
            "Epoch 544/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0819 - accuracy: 0.1841 - val_loss: 0.3745 - val_accuracy: 0.1876\n",
            "Epoch 545/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0826 - accuracy: 0.1841 - val_loss: 0.3744 - val_accuracy: 0.1884\n",
            "Epoch 546/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0815 - accuracy: 0.1841 - val_loss: 0.3915 - val_accuracy: 0.1884\n",
            "Epoch 547/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0856 - accuracy: 0.1841 - val_loss: 0.3764 - val_accuracy: 0.1884\n",
            "Epoch 548/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0812 - accuracy: 0.1841 - val_loss: 0.3792 - val_accuracy: 0.1884\n",
            "Epoch 549/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0831 - accuracy: 0.1841 - val_loss: 0.3798 - val_accuracy: 0.1884\n",
            "Epoch 550/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0827 - accuracy: 0.1841 - val_loss: 0.3773 - val_accuracy: 0.1884\n",
            "Epoch 551/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0797 - accuracy: 0.1841 - val_loss: 0.3688 - val_accuracy: 0.1884\n",
            "Epoch 552/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0798 - accuracy: 0.1841 - val_loss: 0.3734 - val_accuracy: 0.1884\n",
            "Epoch 553/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0833 - accuracy: 0.1841 - val_loss: 0.3615 - val_accuracy: 0.1884\n",
            "Epoch 554/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0769 - accuracy: 0.1841 - val_loss: 0.3767 - val_accuracy: 0.1884\n",
            "Epoch 555/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0818 - accuracy: 0.1841 - val_loss: 0.3787 - val_accuracy: 0.1884\n",
            "Epoch 556/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0858 - accuracy: 0.1841 - val_loss: 0.3748 - val_accuracy: 0.1884\n",
            "Epoch 557/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0821 - accuracy: 0.1841 - val_loss: 0.3687 - val_accuracy: 0.1884\n",
            "Epoch 558/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0811 - accuracy: 0.1841 - val_loss: 0.3906 - val_accuracy: 0.1884\n",
            "Epoch 559/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0823 - accuracy: 0.1841 - val_loss: 0.3749 - val_accuracy: 0.1876\n",
            "Epoch 560/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0856 - accuracy: 0.1841 - val_loss: 0.3873 - val_accuracy: 0.1884\n",
            "Epoch 561/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0857 - accuracy: 0.1841 - val_loss: 0.3659 - val_accuracy: 0.1884\n",
            "Epoch 562/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0862 - accuracy: 0.1841 - val_loss: 0.3715 - val_accuracy: 0.1884\n",
            "Epoch 563/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0820 - accuracy: 0.1841 - val_loss: 0.3753 - val_accuracy: 0.1884\n",
            "Epoch 564/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0821 - accuracy: 0.1841 - val_loss: 0.3768 - val_accuracy: 0.1884\n",
            "Epoch 565/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0855 - accuracy: 0.1841 - val_loss: 0.3703 - val_accuracy: 0.1884\n",
            "Epoch 566/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0782 - accuracy: 0.1841 - val_loss: 0.3747 - val_accuracy: 0.1884\n",
            "Epoch 567/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0766 - accuracy: 0.1841 - val_loss: 0.3787 - val_accuracy: 0.1884\n",
            "Epoch 568/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0835 - accuracy: 0.1835 - val_loss: 0.3685 - val_accuracy: 0.1884\n",
            "Epoch 569/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0830 - accuracy: 0.1841 - val_loss: 0.3766 - val_accuracy: 0.1884\n",
            "Epoch 570/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0823 - accuracy: 0.1841 - val_loss: 0.3582 - val_accuracy: 0.1884\n",
            "Epoch 571/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0762 - accuracy: 0.1841 - val_loss: 0.3621 - val_accuracy: 0.1884\n",
            "Epoch 572/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0813 - accuracy: 0.1841 - val_loss: 0.3641 - val_accuracy: 0.1884\n",
            "Epoch 573/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0790 - accuracy: 0.1841 - val_loss: 0.3794 - val_accuracy: 0.1884\n",
            "Epoch 574/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0791 - accuracy: 0.1841 - val_loss: 0.3532 - val_accuracy: 0.1884\n",
            "Epoch 575/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0806 - accuracy: 0.1835 - val_loss: 0.3709 - val_accuracy: 0.1884\n",
            "Epoch 576/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0746 - accuracy: 0.1841 - val_loss: 0.3828 - val_accuracy: 0.1884\n",
            "Epoch 577/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0793 - accuracy: 0.1841 - val_loss: 0.3757 - val_accuracy: 0.1884\n",
            "Epoch 578/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0814 - accuracy: 0.1841 - val_loss: 0.3724 - val_accuracy: 0.1884\n",
            "Epoch 579/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0760 - accuracy: 0.1841 - val_loss: 0.3742 - val_accuracy: 0.1884\n",
            "Epoch 580/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0871 - accuracy: 0.1841 - val_loss: 0.3792 - val_accuracy: 0.1884\n",
            "Epoch 581/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0820 - accuracy: 0.1841 - val_loss: 0.3685 - val_accuracy: 0.1884\n",
            "Epoch 582/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0777 - accuracy: 0.1841 - val_loss: 0.3716 - val_accuracy: 0.1884\n",
            "Epoch 583/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0842 - accuracy: 0.1841 - val_loss: 0.3688 - val_accuracy: 0.1884\n",
            "Epoch 584/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0799 - accuracy: 0.1841 - val_loss: 0.3610 - val_accuracy: 0.1876\n",
            "Epoch 585/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0842 - accuracy: 0.1841 - val_loss: 0.3704 - val_accuracy: 0.1884\n",
            "Epoch 586/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0828 - accuracy: 0.1841 - val_loss: 0.3613 - val_accuracy: 0.1884\n",
            "Epoch 587/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0810 - accuracy: 0.1841 - val_loss: 0.3638 - val_accuracy: 0.1884\n",
            "Epoch 588/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0735 - accuracy: 0.1841 - val_loss: 0.3835 - val_accuracy: 0.1884\n",
            "Epoch 589/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0799 - accuracy: 0.1841 - val_loss: 0.3671 - val_accuracy: 0.1884\n",
            "Epoch 590/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0798 - accuracy: 0.1841 - val_loss: 0.3689 - val_accuracy: 0.1884\n",
            "Epoch 591/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0773 - accuracy: 0.1839 - val_loss: 0.3592 - val_accuracy: 0.1884\n",
            "Epoch 592/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0722 - accuracy: 0.1841 - val_loss: 0.3689 - val_accuracy: 0.1884\n",
            "Epoch 593/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0840 - accuracy: 0.1841 - val_loss: 0.3589 - val_accuracy: 0.1884\n",
            "Epoch 594/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0789 - accuracy: 0.1841 - val_loss: 0.3753 - val_accuracy: 0.1884\n",
            "Epoch 595/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0802 - accuracy: 0.1841 - val_loss: 0.3781 - val_accuracy: 0.1884\n",
            "Epoch 596/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0743 - accuracy: 0.1841 - val_loss: 0.3675 - val_accuracy: 0.1884\n",
            "Epoch 597/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0765 - accuracy: 0.1841 - val_loss: 0.3688 - val_accuracy: 0.1884\n",
            "Epoch 598/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0815 - accuracy: 0.1841 - val_loss: 0.3594 - val_accuracy: 0.1884\n",
            "Epoch 599/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0727 - accuracy: 0.1841 - val_loss: 0.3679 - val_accuracy: 0.1884\n",
            "Epoch 600/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0809 - accuracy: 0.1841 - val_loss: 0.3693 - val_accuracy: 0.1884\n",
            "Epoch 601/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0811 - accuracy: 0.1841 - val_loss: 0.3706 - val_accuracy: 0.1884\n",
            "Epoch 602/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0775 - accuracy: 0.1841 - val_loss: 0.3652 - val_accuracy: 0.1884\n",
            "Epoch 603/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0757 - accuracy: 0.1841 - val_loss: 0.3695 - val_accuracy: 0.1884\n",
            "Epoch 604/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0807 - accuracy: 0.1841 - val_loss: 0.3810 - val_accuracy: 0.1884\n",
            "Epoch 605/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0784 - accuracy: 0.1841 - val_loss: 0.3677 - val_accuracy: 0.1884\n",
            "Epoch 606/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0745 - accuracy: 0.1841 - val_loss: 0.3672 - val_accuracy: 0.1884\n",
            "Epoch 607/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0733 - accuracy: 0.1841 - val_loss: 0.3636 - val_accuracy: 0.1884\n",
            "Epoch 608/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0761 - accuracy: 0.1841 - val_loss: 0.3625 - val_accuracy: 0.1884\n",
            "Epoch 609/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0785 - accuracy: 0.1841 - val_loss: 0.3828 - val_accuracy: 0.1884\n",
            "Epoch 610/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0746 - accuracy: 0.1841 - val_loss: 0.3645 - val_accuracy: 0.1884\n",
            "Epoch 611/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0773 - accuracy: 0.1841 - val_loss: 0.3587 - val_accuracy: 0.1884\n",
            "Epoch 612/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0739 - accuracy: 0.1841 - val_loss: 0.3623 - val_accuracy: 0.1876\n",
            "Epoch 613/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0747 - accuracy: 0.1841 - val_loss: 0.3704 - val_accuracy: 0.1884\n",
            "Epoch 614/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0827 - accuracy: 0.1841 - val_loss: 0.3678 - val_accuracy: 0.1884\n",
            "Epoch 615/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0739 - accuracy: 0.1841 - val_loss: 0.3682 - val_accuracy: 0.1884\n",
            "Epoch 616/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0724 - accuracy: 0.1841 - val_loss: 0.3558 - val_accuracy: 0.1884\n",
            "Epoch 617/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0736 - accuracy: 0.1835 - val_loss: 0.3755 - val_accuracy: 0.1884\n",
            "Epoch 618/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0680 - accuracy: 0.1841 - val_loss: 0.3690 - val_accuracy: 0.1884\n",
            "Epoch 619/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0733 - accuracy: 0.1841 - val_loss: 0.3659 - val_accuracy: 0.1884\n",
            "Epoch 620/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0725 - accuracy: 0.1841 - val_loss: 0.3547 - val_accuracy: 0.1884\n",
            "Epoch 621/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0727 - accuracy: 0.1841 - val_loss: 0.3690 - val_accuracy: 0.1884\n",
            "Epoch 622/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0782 - accuracy: 0.1841 - val_loss: 0.3815 - val_accuracy: 0.1884\n",
            "Epoch 623/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0728 - accuracy: 0.1841 - val_loss: 0.3696 - val_accuracy: 0.1884\n",
            "Epoch 624/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0814 - accuracy: 0.1835 - val_loss: 0.3596 - val_accuracy: 0.1884\n",
            "Epoch 625/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0726 - accuracy: 0.1841 - val_loss: 0.3699 - val_accuracy: 0.1884\n",
            "Epoch 626/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0751 - accuracy: 0.1841 - val_loss: 0.3670 - val_accuracy: 0.1884\n",
            "Epoch 627/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0689 - accuracy: 0.1841 - val_loss: 0.3674 - val_accuracy: 0.1884\n",
            "Epoch 628/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0754 - accuracy: 0.1841 - val_loss: 0.3670 - val_accuracy: 0.1884\n",
            "Epoch 629/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0748 - accuracy: 0.1841 - val_loss: 0.3690 - val_accuracy: 0.1884\n",
            "Epoch 630/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0774 - accuracy: 0.1835 - val_loss: 0.3745 - val_accuracy: 0.1884\n",
            "Epoch 631/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0771 - accuracy: 0.1841 - val_loss: 0.3747 - val_accuracy: 0.1884\n",
            "Epoch 632/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0747 - accuracy: 0.1841 - val_loss: 0.3628 - val_accuracy: 0.1884\n",
            "Epoch 633/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0754 - accuracy: 0.1841 - val_loss: 0.3717 - val_accuracy: 0.1884\n",
            "Epoch 634/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0790 - accuracy: 0.1841 - val_loss: 0.3701 - val_accuracy: 0.1884\n",
            "Epoch 635/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0738 - accuracy: 0.1841 - val_loss: 0.3669 - val_accuracy: 0.1876\n",
            "Epoch 636/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0755 - accuracy: 0.1841 - val_loss: 0.3707 - val_accuracy: 0.1884\n",
            "Epoch 637/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0778 - accuracy: 0.1841 - val_loss: 0.3743 - val_accuracy: 0.1884\n",
            "Epoch 638/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0768 - accuracy: 0.1841 - val_loss: 0.3669 - val_accuracy: 0.1884\n",
            "Epoch 639/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0782 - accuracy: 0.1841 - val_loss: 0.3617 - val_accuracy: 0.1884\n",
            "Epoch 640/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0705 - accuracy: 0.1841 - val_loss: 0.3697 - val_accuracy: 0.1884\n",
            "Epoch 641/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0768 - accuracy: 0.1841 - val_loss: 0.3692 - val_accuracy: 0.1884\n",
            "Epoch 642/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0709 - accuracy: 0.1841 - val_loss: 0.3561 - val_accuracy: 0.1884\n",
            "Epoch 643/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0709 - accuracy: 0.1835 - val_loss: 0.3613 - val_accuracy: 0.1884\n",
            "Epoch 644/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0696 - accuracy: 0.1841 - val_loss: 0.3663 - val_accuracy: 0.1884\n",
            "Epoch 645/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0793 - accuracy: 0.1841 - val_loss: 0.3706 - val_accuracy: 0.1884\n",
            "Epoch 646/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0701 - accuracy: 0.1841 - val_loss: 0.3658 - val_accuracy: 0.1884\n",
            "Epoch 647/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0707 - accuracy: 0.1841 - val_loss: 0.3629 - val_accuracy: 0.1884\n",
            "Epoch 648/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0745 - accuracy: 0.1835 - val_loss: 0.3644 - val_accuracy: 0.1884\n",
            "Epoch 649/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0752 - accuracy: 0.1839 - val_loss: 0.3672 - val_accuracy: 0.1884\n",
            "Epoch 650/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0676 - accuracy: 0.1841 - val_loss: 0.3717 - val_accuracy: 0.1884\n",
            "Epoch 651/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0737 - accuracy: 0.1841 - val_loss: 0.3667 - val_accuracy: 0.1884\n",
            "Epoch 652/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0761 - accuracy: 0.1841 - val_loss: 0.3723 - val_accuracy: 0.1884\n",
            "Epoch 653/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0742 - accuracy: 0.1841 - val_loss: 0.3627 - val_accuracy: 0.1884\n",
            "Epoch 654/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0687 - accuracy: 0.1841 - val_loss: 0.3574 - val_accuracy: 0.1884\n",
            "Epoch 655/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0731 - accuracy: 0.1841 - val_loss: 0.3715 - val_accuracy: 0.1876\n",
            "Epoch 656/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0769 - accuracy: 0.1841 - val_loss: 0.3653 - val_accuracy: 0.1884\n",
            "Epoch 657/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0764 - accuracy: 0.1841 - val_loss: 0.3650 - val_accuracy: 0.1884\n",
            "Epoch 658/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0723 - accuracy: 0.1841 - val_loss: 0.3791 - val_accuracy: 0.1876\n",
            "Epoch 659/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0767 - accuracy: 0.1841 - val_loss: 0.3613 - val_accuracy: 0.1884\n",
            "Epoch 660/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0667 - accuracy: 0.1841 - val_loss: 0.3646 - val_accuracy: 0.1884\n",
            "Epoch 661/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0660 - accuracy: 0.1841 - val_loss: 0.3595 - val_accuracy: 0.1884\n",
            "Epoch 662/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0689 - accuracy: 0.1841 - val_loss: 0.3671 - val_accuracy: 0.1884\n",
            "Epoch 663/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0753 - accuracy: 0.1841 - val_loss: 0.3701 - val_accuracy: 0.1884\n",
            "Epoch 664/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0717 - accuracy: 0.1839 - val_loss: 0.3595 - val_accuracy: 0.1884\n",
            "Epoch 665/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0686 - accuracy: 0.1835 - val_loss: 0.3607 - val_accuracy: 0.1884\n",
            "Epoch 666/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0756 - accuracy: 0.1841 - val_loss: 0.3549 - val_accuracy: 0.1884\n",
            "Epoch 667/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0660 - accuracy: 0.1841 - val_loss: 0.3646 - val_accuracy: 0.1884\n",
            "Epoch 668/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0705 - accuracy: 0.1839 - val_loss: 0.3610 - val_accuracy: 0.1884\n",
            "Epoch 669/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0704 - accuracy: 0.1841 - val_loss: 0.3708 - val_accuracy: 0.1884\n",
            "Epoch 670/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0742 - accuracy: 0.1841 - val_loss: 0.3582 - val_accuracy: 0.1884\n",
            "Epoch 671/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0677 - accuracy: 0.1841 - val_loss: 0.3602 - val_accuracy: 0.1884\n",
            "Epoch 672/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0721 - accuracy: 0.1839 - val_loss: 0.3632 - val_accuracy: 0.1884\n",
            "Epoch 673/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0690 - accuracy: 0.1841 - val_loss: 0.3725 - val_accuracy: 0.1884\n",
            "Epoch 674/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0785 - accuracy: 0.1841 - val_loss: 0.3590 - val_accuracy: 0.1884\n",
            "Epoch 675/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0722 - accuracy: 0.1841 - val_loss: 0.3625 - val_accuracy: 0.1884\n",
            "Epoch 676/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0667 - accuracy: 0.1841 - val_loss: 0.3671 - val_accuracy: 0.1884\n",
            "Epoch 677/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0741 - accuracy: 0.1841 - val_loss: 0.3583 - val_accuracy: 0.1884\n",
            "Epoch 678/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0688 - accuracy: 0.1841 - val_loss: 0.3602 - val_accuracy: 0.1884\n",
            "Epoch 679/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0728 - accuracy: 0.1835 - val_loss: 0.3589 - val_accuracy: 0.1884\n",
            "Epoch 680/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0707 - accuracy: 0.1841 - val_loss: 0.3703 - val_accuracy: 0.1884\n",
            "Epoch 681/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0718 - accuracy: 0.1841 - val_loss: 0.3609 - val_accuracy: 0.1884\n",
            "Epoch 682/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0671 - accuracy: 0.1839 - val_loss: 0.3569 - val_accuracy: 0.1884\n",
            "Epoch 683/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0661 - accuracy: 0.1841 - val_loss: 0.3700 - val_accuracy: 0.1884\n",
            "Epoch 684/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0702 - accuracy: 0.1841 - val_loss: 0.3515 - val_accuracy: 0.1884\n",
            "Epoch 685/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0705 - accuracy: 0.1841 - val_loss: 0.3773 - val_accuracy: 0.1884\n",
            "Epoch 686/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0767 - accuracy: 0.1841 - val_loss: 0.3808 - val_accuracy: 0.1884\n",
            "Epoch 687/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0738 - accuracy: 0.1841 - val_loss: 0.3643 - val_accuracy: 0.1884\n",
            "Epoch 688/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0654 - accuracy: 0.1841 - val_loss: 0.3664 - val_accuracy: 0.1884\n",
            "Epoch 689/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0732 - accuracy: 0.1841 - val_loss: 0.3564 - val_accuracy: 0.1884\n",
            "Epoch 690/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0644 - accuracy: 0.1841 - val_loss: 0.3750 - val_accuracy: 0.1884\n",
            "Epoch 691/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0706 - accuracy: 0.1841 - val_loss: 0.3629 - val_accuracy: 0.1884\n",
            "Epoch 692/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0686 - accuracy: 0.1841 - val_loss: 0.3558 - val_accuracy: 0.1884\n",
            "Epoch 693/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0703 - accuracy: 0.1841 - val_loss: 0.3725 - val_accuracy: 0.1884\n",
            "Epoch 694/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0671 - accuracy: 0.1841 - val_loss: 0.3644 - val_accuracy: 0.1884\n",
            "Epoch 695/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0654 - accuracy: 0.1841 - val_loss: 0.3582 - val_accuracy: 0.1884\n",
            "Epoch 696/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0719 - accuracy: 0.1841 - val_loss: 0.3590 - val_accuracy: 0.1884\n",
            "Epoch 697/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0641 - accuracy: 0.1841 - val_loss: 0.3591 - val_accuracy: 0.1884\n",
            "Epoch 698/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0671 - accuracy: 0.1841 - val_loss: 0.3595 - val_accuracy: 0.1884\n",
            "Epoch 699/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0715 - accuracy: 0.1841 - val_loss: 0.3650 - val_accuracy: 0.1876\n",
            "Epoch 700/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0718 - accuracy: 0.1841 - val_loss: 0.3780 - val_accuracy: 0.1884\n",
            "Epoch 701/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0772 - accuracy: 0.1841 - val_loss: 0.3581 - val_accuracy: 0.1884\n",
            "Epoch 702/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0705 - accuracy: 0.1841 - val_loss: 0.3679 - val_accuracy: 0.1884\n",
            "Epoch 703/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0688 - accuracy: 0.1841 - val_loss: 0.3547 - val_accuracy: 0.1884\n",
            "Epoch 704/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0699 - accuracy: 0.1841 - val_loss: 0.3688 - val_accuracy: 0.1884\n",
            "Epoch 705/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0654 - accuracy: 0.1841 - val_loss: 0.3607 - val_accuracy: 0.1884\n",
            "Epoch 706/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0692 - accuracy: 0.1841 - val_loss: 0.3644 - val_accuracy: 0.1884\n",
            "Epoch 707/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0729 - accuracy: 0.1841 - val_loss: 0.3707 - val_accuracy: 0.1884\n",
            "Epoch 708/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0649 - accuracy: 0.1841 - val_loss: 0.3598 - val_accuracy: 0.1884\n",
            "Epoch 709/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0688 - accuracy: 0.1841 - val_loss: 0.3612 - val_accuracy: 0.1884\n",
            "Epoch 710/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0721 - accuracy: 0.1841 - val_loss: 0.3718 - val_accuracy: 0.1884\n",
            "Epoch 711/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0685 - accuracy: 0.1841 - val_loss: 0.3701 - val_accuracy: 0.1884\n",
            "Epoch 712/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0665 - accuracy: 0.1841 - val_loss: 0.3491 - val_accuracy: 0.1884\n",
            "Epoch 713/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0695 - accuracy: 0.1841 - val_loss: 0.3685 - val_accuracy: 0.1884\n",
            "Epoch 714/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0724 - accuracy: 0.1835 - val_loss: 0.3715 - val_accuracy: 0.1884\n",
            "Epoch 715/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0682 - accuracy: 0.1841 - val_loss: 0.3573 - val_accuracy: 0.1884\n",
            "Epoch 716/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0690 - accuracy: 0.1841 - val_loss: 0.3561 - val_accuracy: 0.1884\n",
            "Epoch 717/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0663 - accuracy: 0.1835 - val_loss: 0.3596 - val_accuracy: 0.1884\n",
            "Epoch 718/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0648 - accuracy: 0.1841 - val_loss: 0.3541 - val_accuracy: 0.1884\n",
            "Epoch 719/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0630 - accuracy: 0.1841 - val_loss: 0.3676 - val_accuracy: 0.1876\n",
            "Epoch 720/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0695 - accuracy: 0.1841 - val_loss: 0.3646 - val_accuracy: 0.1884\n",
            "Epoch 721/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0744 - accuracy: 0.1841 - val_loss: 0.3685 - val_accuracy: 0.1884\n",
            "Epoch 722/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0660 - accuracy: 0.1841 - val_loss: 0.3510 - val_accuracy: 0.1884\n",
            "Epoch 723/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0665 - accuracy: 0.1841 - val_loss: 0.3592 - val_accuracy: 0.1884\n",
            "Epoch 724/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0626 - accuracy: 0.1841 - val_loss: 0.3616 - val_accuracy: 0.1884\n",
            "Epoch 725/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0656 - accuracy: 0.1841 - val_loss: 0.3545 - val_accuracy: 0.1884\n",
            "Epoch 726/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0633 - accuracy: 0.1841 - val_loss: 0.3750 - val_accuracy: 0.1884\n",
            "Epoch 727/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0728 - accuracy: 0.1841 - val_loss: 0.3488 - val_accuracy: 0.1884\n",
            "Epoch 728/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0733 - accuracy: 0.1841 - val_loss: 0.3612 - val_accuracy: 0.1884\n",
            "Epoch 729/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0647 - accuracy: 0.1841 - val_loss: 0.3722 - val_accuracy: 0.1884\n",
            "Epoch 730/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0722 - accuracy: 0.1841 - val_loss: 0.3656 - val_accuracy: 0.1884\n",
            "Epoch 731/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0639 - accuracy: 0.1841 - val_loss: 0.3633 - val_accuracy: 0.1884\n",
            "Epoch 732/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0706 - accuracy: 0.1839 - val_loss: 0.3567 - val_accuracy: 0.1884\n",
            "Epoch 733/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0647 - accuracy: 0.1841 - val_loss: 0.3736 - val_accuracy: 0.1884\n",
            "Epoch 734/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0730 - accuracy: 0.1841 - val_loss: 0.3509 - val_accuracy: 0.1884\n",
            "Epoch 735/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0691 - accuracy: 0.1841 - val_loss: 0.3681 - val_accuracy: 0.1884\n",
            "Epoch 736/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0710 - accuracy: 0.1841 - val_loss: 0.3726 - val_accuracy: 0.1884\n",
            "Epoch 737/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0705 - accuracy: 0.1841 - val_loss: 0.3599 - val_accuracy: 0.1884\n",
            "Epoch 738/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0636 - accuracy: 0.1841 - val_loss: 0.3563 - val_accuracy: 0.1884\n",
            "Epoch 739/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0627 - accuracy: 0.1841 - val_loss: 0.3660 - val_accuracy: 0.1884\n",
            "Epoch 740/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0642 - accuracy: 0.1841 - val_loss: 0.3532 - val_accuracy: 0.1884\n",
            "Epoch 741/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0683 - accuracy: 0.1841 - val_loss: 0.3572 - val_accuracy: 0.1884\n",
            "Epoch 742/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0699 - accuracy: 0.1841 - val_loss: 0.3665 - val_accuracy: 0.1884\n",
            "Epoch 743/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0617 - accuracy: 0.1841 - val_loss: 0.3508 - val_accuracy: 0.1884\n",
            "Epoch 744/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0694 - accuracy: 0.1841 - val_loss: 0.3607 - val_accuracy: 0.1884\n",
            "Epoch 745/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0712 - accuracy: 0.1841 - val_loss: 0.3583 - val_accuracy: 0.1884\n",
            "Epoch 746/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0749 - accuracy: 0.1841 - val_loss: 0.3556 - val_accuracy: 0.1884\n",
            "Epoch 747/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0633 - accuracy: 0.1841 - val_loss: 0.3626 - val_accuracy: 0.1884\n",
            "Epoch 748/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0641 - accuracy: 0.1841 - val_loss: 0.3566 - val_accuracy: 0.1884\n",
            "Epoch 749/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0616 - accuracy: 0.1841 - val_loss: 0.3650 - val_accuracy: 0.1884\n",
            "Epoch 750/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0692 - accuracy: 0.1841 - val_loss: 0.3569 - val_accuracy: 0.1884\n",
            "Epoch 751/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0677 - accuracy: 0.1841 - val_loss: 0.3618 - val_accuracy: 0.1884\n",
            "Epoch 752/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0663 - accuracy: 0.1841 - val_loss: 0.3552 - val_accuracy: 0.1884\n",
            "Epoch 753/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0646 - accuracy: 0.1841 - val_loss: 0.3674 - val_accuracy: 0.1884\n",
            "Epoch 754/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0680 - accuracy: 0.1841 - val_loss: 0.3630 - val_accuracy: 0.1884\n",
            "Epoch 755/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0661 - accuracy: 0.1841 - val_loss: 0.3629 - val_accuracy: 0.1884\n",
            "Epoch 756/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0646 - accuracy: 0.1841 - val_loss: 0.3703 - val_accuracy: 0.1884\n",
            "Epoch 757/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0665 - accuracy: 0.1841 - val_loss: 0.3589 - val_accuracy: 0.1884\n",
            "Epoch 758/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0622 - accuracy: 0.1841 - val_loss: 0.3571 - val_accuracy: 0.1884\n",
            "Epoch 759/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0644 - accuracy: 0.1841 - val_loss: 0.3555 - val_accuracy: 0.1884\n",
            "Epoch 760/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0613 - accuracy: 0.1841 - val_loss: 0.3489 - val_accuracy: 0.1884\n",
            "Epoch 761/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0629 - accuracy: 0.1841 - val_loss: 0.3551 - val_accuracy: 0.1884\n",
            "Epoch 762/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0625 - accuracy: 0.1841 - val_loss: 0.3631 - val_accuracy: 0.1884\n",
            "Epoch 763/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0616 - accuracy: 0.1841 - val_loss: 0.3521 - val_accuracy: 0.1884\n",
            "Epoch 764/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0668 - accuracy: 0.1841 - val_loss: 0.3581 - val_accuracy: 0.1884\n",
            "Epoch 765/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0628 - accuracy: 0.1841 - val_loss: 0.3586 - val_accuracy: 0.1884\n",
            "Epoch 766/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0642 - accuracy: 0.1841 - val_loss: 0.3513 - val_accuracy: 0.1884\n",
            "Epoch 767/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0672 - accuracy: 0.1841 - val_loss: 0.3608 - val_accuracy: 0.1884\n",
            "Epoch 768/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0592 - accuracy: 0.1841 - val_loss: 0.3595 - val_accuracy: 0.1884\n",
            "Epoch 769/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0719 - accuracy: 0.1841 - val_loss: 0.3570 - val_accuracy: 0.1884\n",
            "Epoch 770/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0621 - accuracy: 0.1841 - val_loss: 0.3622 - val_accuracy: 0.1884\n",
            "Epoch 771/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0656 - accuracy: 0.1841 - val_loss: 0.3662 - val_accuracy: 0.1884\n",
            "Epoch 772/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0706 - accuracy: 0.1841 - val_loss: 0.3576 - val_accuracy: 0.1884\n",
            "Epoch 773/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0608 - accuracy: 0.1841 - val_loss: 0.3512 - val_accuracy: 0.1884\n",
            "Epoch 774/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0652 - accuracy: 0.1841 - val_loss: 0.3729 - val_accuracy: 0.1884\n",
            "Epoch 775/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0670 - accuracy: 0.1841 - val_loss: 0.3630 - val_accuracy: 0.1884\n",
            "Epoch 776/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0650 - accuracy: 0.1841 - val_loss: 0.3646 - val_accuracy: 0.1884\n",
            "Epoch 777/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0653 - accuracy: 0.1841 - val_loss: 0.3675 - val_accuracy: 0.1884\n",
            "Epoch 778/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0615 - accuracy: 0.1841 - val_loss: 0.3514 - val_accuracy: 0.1884\n",
            "Epoch 779/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0634 - accuracy: 0.1841 - val_loss: 0.3521 - val_accuracy: 0.1884\n",
            "Epoch 780/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0637 - accuracy: 0.1841 - val_loss: 0.3724 - val_accuracy: 0.1884\n",
            "Epoch 781/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0649 - accuracy: 0.1841 - val_loss: 0.3650 - val_accuracy: 0.1884\n",
            "Epoch 782/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0653 - accuracy: 0.1841 - val_loss: 0.3600 - val_accuracy: 0.1884\n",
            "Epoch 783/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0662 - accuracy: 0.1841 - val_loss: 0.3525 - val_accuracy: 0.1884\n",
            "Epoch 784/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0660 - accuracy: 0.1841 - val_loss: 0.3692 - val_accuracy: 0.1884\n",
            "Epoch 785/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0617 - accuracy: 0.1841 - val_loss: 0.3558 - val_accuracy: 0.1884\n",
            "Epoch 786/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0676 - accuracy: 0.1841 - val_loss: 0.3578 - val_accuracy: 0.1884\n",
            "Epoch 787/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0665 - accuracy: 0.1841 - val_loss: 0.3624 - val_accuracy: 0.1884\n",
            "Epoch 788/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0672 - accuracy: 0.1841 - val_loss: 0.3593 - val_accuracy: 0.1884\n",
            "Epoch 789/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0658 - accuracy: 0.1841 - val_loss: 0.3594 - val_accuracy: 0.1884\n",
            "Epoch 790/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0590 - accuracy: 0.1841 - val_loss: 0.3537 - val_accuracy: 0.1884\n",
            "Epoch 791/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0720 - accuracy: 0.1841 - val_loss: 0.3657 - val_accuracy: 0.1884\n",
            "Epoch 792/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0602 - accuracy: 0.1841 - val_loss: 0.3502 - val_accuracy: 0.1884\n",
            "Epoch 793/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0639 - accuracy: 0.1841 - val_loss: 0.3602 - val_accuracy: 0.1884\n",
            "Epoch 794/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0633 - accuracy: 0.1841 - val_loss: 0.3642 - val_accuracy: 0.1884\n",
            "Epoch 795/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0616 - accuracy: 0.1841 - val_loss: 0.3590 - val_accuracy: 0.1884\n",
            "Epoch 796/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0645 - accuracy: 0.1841 - val_loss: 0.3601 - val_accuracy: 0.1884\n",
            "Epoch 797/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0617 - accuracy: 0.1841 - val_loss: 0.3699 - val_accuracy: 0.1884\n",
            "Epoch 798/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0659 - accuracy: 0.1841 - val_loss: 0.3536 - val_accuracy: 0.1884\n",
            "Epoch 799/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0706 - accuracy: 0.1841 - val_loss: 0.3552 - val_accuracy: 0.1884\n",
            "Epoch 800/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0684 - accuracy: 0.1841 - val_loss: 0.3613 - val_accuracy: 0.1884\n",
            "Epoch 801/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0635 - accuracy: 0.1841 - val_loss: 0.3555 - val_accuracy: 0.1884\n",
            "Epoch 802/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0607 - accuracy: 0.1841 - val_loss: 0.3673 - val_accuracy: 0.1884\n",
            "Epoch 803/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0636 - accuracy: 0.1841 - val_loss: 0.3561 - val_accuracy: 0.1884\n",
            "Epoch 804/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0654 - accuracy: 0.1841 - val_loss: 0.3434 - val_accuracy: 0.1884\n",
            "Epoch 805/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0587 - accuracy: 0.1841 - val_loss: 0.3569 - val_accuracy: 0.1884\n",
            "Epoch 806/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0657 - accuracy: 0.1841 - val_loss: 0.3557 - val_accuracy: 0.1884\n",
            "Epoch 807/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0635 - accuracy: 0.1841 - val_loss: 0.3592 - val_accuracy: 0.1884\n",
            "Epoch 808/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0642 - accuracy: 0.1841 - val_loss: 0.3613 - val_accuracy: 0.1884\n",
            "Epoch 809/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0705 - accuracy: 0.1841 - val_loss: 0.3695 - val_accuracy: 0.1884\n",
            "Epoch 810/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0646 - accuracy: 0.1841 - val_loss: 0.3493 - val_accuracy: 0.1884\n",
            "Epoch 811/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0634 - accuracy: 0.1841 - val_loss: 0.3599 - val_accuracy: 0.1884\n",
            "Epoch 812/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 0.0597 - accuracy: 0.1841 - val_loss: 0.3631 - val_accuracy: 0.1884\n",
            "Epoch 813/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0615 - accuracy: 0.1841 - val_loss: 0.3614 - val_accuracy: 0.1884\n",
            "Epoch 814/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0678 - accuracy: 0.1841 - val_loss: 0.3556 - val_accuracy: 0.1884\n",
            "Epoch 815/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0580 - accuracy: 0.1841 - val_loss: 0.3633 - val_accuracy: 0.1884\n",
            "Epoch 816/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0615 - accuracy: 0.1841 - val_loss: 0.3628 - val_accuracy: 0.1884\n",
            "Epoch 817/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0689 - accuracy: 0.1841 - val_loss: 0.3546 - val_accuracy: 0.1884\n",
            "Epoch 818/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0604 - accuracy: 0.1841 - val_loss: 0.3553 - val_accuracy: 0.1884\n",
            "Epoch 819/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0643 - accuracy: 0.1841 - val_loss: 0.3587 - val_accuracy: 0.1884\n",
            "Epoch 820/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0616 - accuracy: 0.1841 - val_loss: 0.3579 - val_accuracy: 0.1884\n",
            "Epoch 821/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0655 - accuracy: 0.1841 - val_loss: 0.3532 - val_accuracy: 0.1884\n",
            "Epoch 822/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0608 - accuracy: 0.1841 - val_loss: 0.3676 - val_accuracy: 0.1884\n",
            "Epoch 823/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0672 - accuracy: 0.1841 - val_loss: 0.3547 - val_accuracy: 0.1884\n",
            "Epoch 824/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0621 - accuracy: 0.1841 - val_loss: 0.3632 - val_accuracy: 0.1884\n",
            "Epoch 825/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0605 - accuracy: 0.1841 - val_loss: 0.3519 - val_accuracy: 0.1884\n",
            "Epoch 826/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0607 - accuracy: 0.1841 - val_loss: 0.3538 - val_accuracy: 0.1884\n",
            "Epoch 827/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0563 - accuracy: 0.1841 - val_loss: 0.3536 - val_accuracy: 0.1884\n",
            "Epoch 828/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0571 - accuracy: 0.1841 - val_loss: 0.3512 - val_accuracy: 0.1884\n",
            "Epoch 829/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 0.0591 - accuracy: 0.1841 - val_loss: 0.3549 - val_accuracy: 0.1884\n",
            "Epoch 830/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 0.0600 - accuracy: 0.1841 - val_loss: 0.3510 - val_accuracy: 0.1884\n",
            "Epoch 831/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0593 - accuracy: 0.1841 - val_loss: 0.3549 - val_accuracy: 0.1884\n",
            "Epoch 832/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0582 - accuracy: 0.1841 - val_loss: 0.3612 - val_accuracy: 0.1884\n",
            "Epoch 833/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0569 - accuracy: 0.1841 - val_loss: 0.3613 - val_accuracy: 0.1884\n",
            "Epoch 834/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0667 - accuracy: 0.1841 - val_loss: 0.3662 - val_accuracy: 0.1884\n",
            "Epoch 835/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0671 - accuracy: 0.1841 - val_loss: 0.3556 - val_accuracy: 0.1884\n",
            "Epoch 836/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0690 - accuracy: 0.1841 - val_loss: 0.3542 - val_accuracy: 0.1884\n",
            "Epoch 837/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0566 - accuracy: 0.1841 - val_loss: 0.3606 - val_accuracy: 0.1884\n",
            "Epoch 838/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0634 - accuracy: 0.1841 - val_loss: 0.3553 - val_accuracy: 0.1884\n",
            "Epoch 839/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0593 - accuracy: 0.1841 - val_loss: 0.3511 - val_accuracy: 0.1884\n",
            "Epoch 840/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0637 - accuracy: 0.1841 - val_loss: 0.3574 - val_accuracy: 0.1884\n",
            "Epoch 841/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0563 - accuracy: 0.1841 - val_loss: 0.3613 - val_accuracy: 0.1884\n",
            "Epoch 842/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0632 - accuracy: 0.1841 - val_loss: 0.3490 - val_accuracy: 0.1884\n",
            "Epoch 843/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0601 - accuracy: 0.1841 - val_loss: 0.3519 - val_accuracy: 0.1884\n",
            "Epoch 844/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0556 - accuracy: 0.1841 - val_loss: 0.3471 - val_accuracy: 0.1884\n",
            "Epoch 845/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0588 - accuracy: 0.1841 - val_loss: 0.3517 - val_accuracy: 0.1884\n",
            "Epoch 846/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0619 - accuracy: 0.1841 - val_loss: 0.3634 - val_accuracy: 0.1884\n",
            "Epoch 847/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0585 - accuracy: 0.1841 - val_loss: 0.3530 - val_accuracy: 0.1884\n",
            "Epoch 848/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0626 - accuracy: 0.1841 - val_loss: 0.3466 - val_accuracy: 0.1884\n",
            "Epoch 849/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0609 - accuracy: 0.1841 - val_loss: 0.3625 - val_accuracy: 0.1884\n",
            "Epoch 850/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0624 - accuracy: 0.1841 - val_loss: 0.3656 - val_accuracy: 0.1884\n",
            "Epoch 851/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0649 - accuracy: 0.1841 - val_loss: 0.3530 - val_accuracy: 0.1884\n",
            "Epoch 852/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0609 - accuracy: 0.1841 - val_loss: 0.3650 - val_accuracy: 0.1884\n",
            "Epoch 853/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0664 - accuracy: 0.1841 - val_loss: 0.3588 - val_accuracy: 0.1884\n",
            "Epoch 854/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0651 - accuracy: 0.1841 - val_loss: 0.3574 - val_accuracy: 0.1884\n",
            "Epoch 855/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0658 - accuracy: 0.1841 - val_loss: 0.3576 - val_accuracy: 0.1884\n",
            "Epoch 856/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0615 - accuracy: 0.1841 - val_loss: 0.3518 - val_accuracy: 0.1884\n",
            "Epoch 857/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0576 - accuracy: 0.1841 - val_loss: 0.3513 - val_accuracy: 0.1884\n",
            "Epoch 858/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0606 - accuracy: 0.1841 - val_loss: 0.3598 - val_accuracy: 0.1884\n",
            "Epoch 859/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0636 - accuracy: 0.1841 - val_loss: 0.3682 - val_accuracy: 0.1884\n",
            "Epoch 860/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0614 - accuracy: 0.1841 - val_loss: 0.3582 - val_accuracy: 0.1884\n",
            "Epoch 861/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0603 - accuracy: 0.1841 - val_loss: 0.3536 - val_accuracy: 0.1884\n",
            "Epoch 862/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0592 - accuracy: 0.1841 - val_loss: 0.3611 - val_accuracy: 0.1884\n",
            "Epoch 863/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0595 - accuracy: 0.1841 - val_loss: 0.3547 - val_accuracy: 0.1884\n",
            "Epoch 864/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0540 - accuracy: 0.1841 - val_loss: 0.3515 - val_accuracy: 0.1884\n",
            "Epoch 865/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0634 - accuracy: 0.1841 - val_loss: 0.3703 - val_accuracy: 0.1884\n",
            "Epoch 866/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0584 - accuracy: 0.1841 - val_loss: 0.3488 - val_accuracy: 0.1884\n",
            "Epoch 867/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0596 - accuracy: 0.1841 - val_loss: 0.3481 - val_accuracy: 0.1884\n",
            "Epoch 868/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0544 - accuracy: 0.1841 - val_loss: 0.3537 - val_accuracy: 0.1884\n",
            "Epoch 869/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0578 - accuracy: 0.1841 - val_loss: 0.3459 - val_accuracy: 0.1884\n",
            "Epoch 870/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0530 - accuracy: 0.1841 - val_loss: 0.3502 - val_accuracy: 0.1884\n",
            "Epoch 871/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0560 - accuracy: 0.1841 - val_loss: 0.3454 - val_accuracy: 0.1884\n",
            "Epoch 872/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0539 - accuracy: 0.1841 - val_loss: 0.3519 - val_accuracy: 0.1884\n",
            "Epoch 873/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0606 - accuracy: 0.1841 - val_loss: 0.3635 - val_accuracy: 0.1884\n",
            "Epoch 874/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0616 - accuracy: 0.1841 - val_loss: 0.3468 - val_accuracy: 0.1884\n",
            "Epoch 875/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0619 - accuracy: 0.1841 - val_loss: 0.3556 - val_accuracy: 0.1884\n",
            "Epoch 876/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0578 - accuracy: 0.1841 - val_loss: 0.3519 - val_accuracy: 0.1884\n",
            "Epoch 877/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0583 - accuracy: 0.1841 - val_loss: 0.3547 - val_accuracy: 0.1884\n",
            "Epoch 878/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0621 - accuracy: 0.1841 - val_loss: 0.3592 - val_accuracy: 0.1884\n",
            "Epoch 879/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0587 - accuracy: 0.1841 - val_loss: 0.3610 - val_accuracy: 0.1884\n",
            "Epoch 880/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0594 - accuracy: 0.1841 - val_loss: 0.3567 - val_accuracy: 0.1884\n",
            "Epoch 881/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0625 - accuracy: 0.1841 - val_loss: 0.3626 - val_accuracy: 0.1884\n",
            "Epoch 882/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0655 - accuracy: 0.1841 - val_loss: 0.3517 - val_accuracy: 0.1884\n",
            "Epoch 883/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0556 - accuracy: 0.1841 - val_loss: 0.3608 - val_accuracy: 0.1884\n",
            "Epoch 884/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0605 - accuracy: 0.1841 - val_loss: 0.3575 - val_accuracy: 0.1884\n",
            "Epoch 885/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0609 - accuracy: 0.1841 - val_loss: 0.3552 - val_accuracy: 0.1884\n",
            "Epoch 886/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0529 - accuracy: 0.1841 - val_loss: 0.3490 - val_accuracy: 0.1884\n",
            "Epoch 887/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0652 - accuracy: 0.1841 - val_loss: 0.3504 - val_accuracy: 0.1884\n",
            "Epoch 888/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0595 - accuracy: 0.1841 - val_loss: 0.3446 - val_accuracy: 0.1884\n",
            "Epoch 889/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0569 - accuracy: 0.1841 - val_loss: 0.3594 - val_accuracy: 0.1884\n",
            "Epoch 890/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0599 - accuracy: 0.1841 - val_loss: 0.3567 - val_accuracy: 0.1884\n",
            "Epoch 891/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0674 - accuracy: 0.1841 - val_loss: 0.3573 - val_accuracy: 0.1884\n",
            "Epoch 892/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0628 - accuracy: 0.1841 - val_loss: 0.3536 - val_accuracy: 0.1884\n",
            "Epoch 893/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0600 - accuracy: 0.1841 - val_loss: 0.3453 - val_accuracy: 0.1884\n",
            "Epoch 894/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0539 - accuracy: 0.1841 - val_loss: 0.3459 - val_accuracy: 0.1884\n",
            "Epoch 895/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0571 - accuracy: 0.1841 - val_loss: 0.3476 - val_accuracy: 0.1884\n",
            "Epoch 896/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0509 - accuracy: 0.1841 - val_loss: 0.3587 - val_accuracy: 0.1884\n",
            "Epoch 897/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0527 - accuracy: 0.1841 - val_loss: 0.3555 - val_accuracy: 0.1884\n",
            "Epoch 898/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0580 - accuracy: 0.1841 - val_loss: 0.3418 - val_accuracy: 0.1884\n",
            "Epoch 899/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0555 - accuracy: 0.1841 - val_loss: 0.3516 - val_accuracy: 0.1884\n",
            "Epoch 900/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0545 - accuracy: 0.1841 - val_loss: 0.3508 - val_accuracy: 0.1884\n",
            "Epoch 901/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0582 - accuracy: 0.1841 - val_loss: 0.3473 - val_accuracy: 0.1884\n",
            "Epoch 902/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0567 - accuracy: 0.1841 - val_loss: 0.3530 - val_accuracy: 0.1884\n",
            "Epoch 903/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0549 - accuracy: 0.1841 - val_loss: 0.3579 - val_accuracy: 0.1884\n",
            "Epoch 904/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0626 - accuracy: 0.1841 - val_loss: 0.3539 - val_accuracy: 0.1884\n",
            "Epoch 905/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0558 - accuracy: 0.1841 - val_loss: 0.3521 - val_accuracy: 0.1884\n",
            "Epoch 906/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0597 - accuracy: 0.1841 - val_loss: 0.3575 - val_accuracy: 0.1884\n",
            "Epoch 907/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0616 - accuracy: 0.1841 - val_loss: 0.3502 - val_accuracy: 0.1884\n",
            "Epoch 908/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0567 - accuracy: 0.1841 - val_loss: 0.3592 - val_accuracy: 0.1884\n",
            "Epoch 909/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0551 - accuracy: 0.1841 - val_loss: 0.3534 - val_accuracy: 0.1884\n",
            "Epoch 910/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0580 - accuracy: 0.1841 - val_loss: 0.3557 - val_accuracy: 0.1884\n",
            "Epoch 911/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0583 - accuracy: 0.1841 - val_loss: 0.3516 - val_accuracy: 0.1884\n",
            "Epoch 912/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0616 - accuracy: 0.1841 - val_loss: 0.3477 - val_accuracy: 0.1884\n",
            "Epoch 913/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0586 - accuracy: 0.1841 - val_loss: 0.3570 - val_accuracy: 0.1884\n",
            "Epoch 914/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0602 - accuracy: 0.1841 - val_loss: 0.3480 - val_accuracy: 0.1884\n",
            "Epoch 915/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0587 - accuracy: 0.1841 - val_loss: 0.3707 - val_accuracy: 0.1884\n",
            "Epoch 916/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0631 - accuracy: 0.1841 - val_loss: 0.3424 - val_accuracy: 0.1884\n",
            "Epoch 917/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0568 - accuracy: 0.1841 - val_loss: 0.3510 - val_accuracy: 0.1884\n",
            "Epoch 918/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0549 - accuracy: 0.1841 - val_loss: 0.3570 - val_accuracy: 0.1884\n",
            "Epoch 919/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0549 - accuracy: 0.1841 - val_loss: 0.3522 - val_accuracy: 0.1884\n",
            "Epoch 920/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0534 - accuracy: 0.1841 - val_loss: 0.3536 - val_accuracy: 0.1884\n",
            "Epoch 921/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0556 - accuracy: 0.1841 - val_loss: 0.3571 - val_accuracy: 0.1884\n",
            "Epoch 922/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0538 - accuracy: 0.1841 - val_loss: 0.3571 - val_accuracy: 0.1884\n",
            "Epoch 923/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0586 - accuracy: 0.1841 - val_loss: 0.3589 - val_accuracy: 0.1884\n",
            "Epoch 924/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0607 - accuracy: 0.1841 - val_loss: 0.3543 - val_accuracy: 0.1884\n",
            "Epoch 925/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0583 - accuracy: 0.1841 - val_loss: 0.3560 - val_accuracy: 0.1884\n",
            "Epoch 926/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0618 - accuracy: 0.1841 - val_loss: 0.3525 - val_accuracy: 0.1884\n",
            "Epoch 927/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0585 - accuracy: 0.1841 - val_loss: 0.3452 - val_accuracy: 0.1884\n",
            "Epoch 928/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0562 - accuracy: 0.1841 - val_loss: 0.3481 - val_accuracy: 0.1884\n",
            "Epoch 929/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0604 - accuracy: 0.1841 - val_loss: 0.3453 - val_accuracy: 0.1884\n",
            "Epoch 930/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0500 - accuracy: 0.1841 - val_loss: 0.3481 - val_accuracy: 0.1884\n",
            "Epoch 931/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0543 - accuracy: 0.1841 - val_loss: 0.3518 - val_accuracy: 0.1884\n",
            "Epoch 932/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0570 - accuracy: 0.1841 - val_loss: 0.3495 - val_accuracy: 0.1884\n",
            "Epoch 933/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0597 - accuracy: 0.1841 - val_loss: 0.3585 - val_accuracy: 0.1884\n",
            "Epoch 934/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0555 - accuracy: 0.1841 - val_loss: 0.3483 - val_accuracy: 0.1884\n",
            "Epoch 935/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0548 - accuracy: 0.1841 - val_loss: 0.3510 - val_accuracy: 0.1884\n",
            "Epoch 936/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0545 - accuracy: 0.1841 - val_loss: 0.3632 - val_accuracy: 0.1884\n",
            "Epoch 937/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0515 - accuracy: 0.1841 - val_loss: 0.3423 - val_accuracy: 0.1884\n",
            "Epoch 938/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0606 - accuracy: 0.1841 - val_loss: 0.3478 - val_accuracy: 0.1884\n",
            "Epoch 939/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0533 - accuracy: 0.1841 - val_loss: 0.3488 - val_accuracy: 0.1884\n",
            "Epoch 940/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0526 - accuracy: 0.1841 - val_loss: 0.3502 - val_accuracy: 0.1884\n",
            "Epoch 941/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0601 - accuracy: 0.1841 - val_loss: 0.3573 - val_accuracy: 0.1884\n",
            "Epoch 942/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0582 - accuracy: 0.1841 - val_loss: 0.3488 - val_accuracy: 0.1884\n",
            "Epoch 943/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0589 - accuracy: 0.1841 - val_loss: 0.3527 - val_accuracy: 0.1884\n",
            "Epoch 944/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0581 - accuracy: 0.1841 - val_loss: 0.3466 - val_accuracy: 0.1884\n",
            "Epoch 945/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0587 - accuracy: 0.1841 - val_loss: 0.3494 - val_accuracy: 0.1884\n",
            "Epoch 946/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0500 - accuracy: 0.1841 - val_loss: 0.3533 - val_accuracy: 0.1884\n",
            "Epoch 947/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0597 - accuracy: 0.1841 - val_loss: 0.3471 - val_accuracy: 0.1884\n",
            "Epoch 948/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0586 - accuracy: 0.1841 - val_loss: 0.3463 - val_accuracy: 0.1884\n",
            "Epoch 949/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0528 - accuracy: 0.1841 - val_loss: 0.3564 - val_accuracy: 0.1884\n",
            "Epoch 950/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0562 - accuracy: 0.1841 - val_loss: 0.3525 - val_accuracy: 0.1884\n",
            "Epoch 951/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0591 - accuracy: 0.1841 - val_loss: 0.3521 - val_accuracy: 0.1884\n",
            "Epoch 952/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0574 - accuracy: 0.1841 - val_loss: 0.3421 - val_accuracy: 0.1884\n",
            "Epoch 953/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0543 - accuracy: 0.1841 - val_loss: 0.3463 - val_accuracy: 0.1884\n",
            "Epoch 954/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0584 - accuracy: 0.1841 - val_loss: 0.3499 - val_accuracy: 0.1884\n",
            "Epoch 955/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0565 - accuracy: 0.1841 - val_loss: 0.3569 - val_accuracy: 0.1884\n",
            "Epoch 956/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0543 - accuracy: 0.1841 - val_loss: 0.3546 - val_accuracy: 0.1884\n",
            "Epoch 957/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0490 - accuracy: 0.1841 - val_loss: 0.3519 - val_accuracy: 0.1884\n",
            "Epoch 958/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0558 - accuracy: 0.1841 - val_loss: 0.3485 - val_accuracy: 0.1884\n",
            "Epoch 959/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0535 - accuracy: 0.1841 - val_loss: 0.3526 - val_accuracy: 0.1884\n",
            "Epoch 960/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0622 - accuracy: 0.1841 - val_loss: 0.3608 - val_accuracy: 0.1884\n",
            "Epoch 961/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0561 - accuracy: 0.1841 - val_loss: 0.3517 - val_accuracy: 0.1884\n",
            "Epoch 962/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0541 - accuracy: 0.1841 - val_loss: 0.3510 - val_accuracy: 0.1884\n",
            "Epoch 963/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0599 - accuracy: 0.1841 - val_loss: 0.3523 - val_accuracy: 0.1884\n",
            "Epoch 964/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0595 - accuracy: 0.1841 - val_loss: 0.3480 - val_accuracy: 0.1884\n",
            "Epoch 965/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0551 - accuracy: 0.1841 - val_loss: 0.3559 - val_accuracy: 0.1884\n",
            "Epoch 966/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0530 - accuracy: 0.1841 - val_loss: 0.3570 - val_accuracy: 0.1884\n",
            "Epoch 967/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0561 - accuracy: 0.1841 - val_loss: 0.3465 - val_accuracy: 0.1884\n",
            "Epoch 968/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0560 - accuracy: 0.1841 - val_loss: 0.3586 - val_accuracy: 0.1884\n",
            "Epoch 969/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0504 - accuracy: 0.1841 - val_loss: 0.3468 - val_accuracy: 0.1884\n",
            "Epoch 970/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0581 - accuracy: 0.1841 - val_loss: 0.3514 - val_accuracy: 0.1884\n",
            "Epoch 971/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0618 - accuracy: 0.1841 - val_loss: 0.3612 - val_accuracy: 0.1884\n",
            "Epoch 972/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0549 - accuracy: 0.1841 - val_loss: 0.3476 - val_accuracy: 0.1884\n",
            "Epoch 973/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0574 - accuracy: 0.1841 - val_loss: 0.3478 - val_accuracy: 0.1884\n",
            "Epoch 974/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0508 - accuracy: 0.1841 - val_loss: 0.3556 - val_accuracy: 0.1884\n",
            "Epoch 975/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0524 - accuracy: 0.1841 - val_loss: 0.3574 - val_accuracy: 0.1884\n",
            "Epoch 976/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0581 - accuracy: 0.1841 - val_loss: 0.3512 - val_accuracy: 0.1884\n",
            "Epoch 977/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0528 - accuracy: 0.1841 - val_loss: 0.3535 - val_accuracy: 0.1884\n",
            "Epoch 978/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0507 - accuracy: 0.1841 - val_loss: 0.3486 - val_accuracy: 0.1884\n",
            "Epoch 979/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0570 - accuracy: 0.1841 - val_loss: 0.3471 - val_accuracy: 0.1884\n",
            "Epoch 980/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0524 - accuracy: 0.1841 - val_loss: 0.3512 - val_accuracy: 0.1884\n",
            "Epoch 981/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0519 - accuracy: 0.1841 - val_loss: 0.3539 - val_accuracy: 0.1884\n",
            "Epoch 982/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0530 - accuracy: 0.1841 - val_loss: 0.3448 - val_accuracy: 0.1884\n",
            "Epoch 983/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0515 - accuracy: 0.1841 - val_loss: 0.3440 - val_accuracy: 0.1884\n",
            "Epoch 984/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0533 - accuracy: 0.1841 - val_loss: 0.3504 - val_accuracy: 0.1884\n",
            "Epoch 985/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0522 - accuracy: 0.1841 - val_loss: 0.3513 - val_accuracy: 0.1884\n",
            "Epoch 986/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 0.0590 - accuracy: 0.1841 - val_loss: 0.3534 - val_accuracy: 0.1884\n",
            "Epoch 987/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0546 - accuracy: 0.1841 - val_loss: 0.3523 - val_accuracy: 0.1884\n",
            "Epoch 988/1000\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 0.0500 - accuracy: 0.1841 - val_loss: 0.3516 - val_accuracy: 0.1884\n",
            "Epoch 989/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0547 - accuracy: 0.1841 - val_loss: 0.3487 - val_accuracy: 0.1884\n",
            "Epoch 990/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0594 - accuracy: 0.1841 - val_loss: 0.3578 - val_accuracy: 0.1884\n",
            "Epoch 991/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0547 - accuracy: 0.1841 - val_loss: 0.3442 - val_accuracy: 0.1884\n",
            "Epoch 992/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0550 - accuracy: 0.1841 - val_loss: 0.3500 - val_accuracy: 0.1884\n",
            "Epoch 993/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0507 - accuracy: 0.1841 - val_loss: 0.3522 - val_accuracy: 0.1884\n",
            "Epoch 994/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0571 - accuracy: 0.1841 - val_loss: 0.3489 - val_accuracy: 0.1884\n",
            "Epoch 995/1000\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.0566 - accuracy: 0.1841 - val_loss: 0.3485 - val_accuracy: 0.1884\n",
            "Epoch 996/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0562 - accuracy: 0.1841 - val_loss: 0.3442 - val_accuracy: 0.1884\n",
            "Epoch 997/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0564 - accuracy: 0.1841 - val_loss: 0.3442 - val_accuracy: 0.1884\n",
            "Epoch 998/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0485 - accuracy: 0.1841 - val_loss: 0.3439 - val_accuracy: 0.1884\n",
            "Epoch 999/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0540 - accuracy: 0.1841 - val_loss: 0.3423 - val_accuracy: 0.1884\n",
            "Epoch 1000/1000\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0541 - accuracy: 0.1841 - val_loss: 0.3516 - val_accuracy: 0.1884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "0dyTXIOBM5KX",
        "outputId": "098c997c-8b4c-47a0-d33a-5b31c49b67c0"
      },
      "source": [
        "# plot history\n",
        "pyplot.subplot(211)\n",
        "pyplot.title('Training and Validation Loss')\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.xlabel('Epochs')\n",
        "pyplot.ylabel('Loss')\n",
        "pyplot.legend()\n",
        "\n",
        "pyplot.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "6USxAIBHNqSO",
        "outputId": "3d05a384-b12c-4513-d906-0d2941e269a4"
      },
      "source": [
        "# plot accuracy during training\n",
        "pyplot.subplot(212)\n",
        "pyplot.title('Training and Validation Accuracy')\n",
        "pyplot.plot(history.history['accuracy'], label='train')\n",
        "pyplot.plot(history.history['val_accuracy'], label='test')\n",
        "pyplot.xlabel('Epochs')\n",
        "pyplot.ylabel('Accuracy')\n",
        "pyplot.legend()\n",
        "\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "it4aNUyvNr8Z",
        "outputId": "ac00ac8e-1f0a-4fb0-8205-21620f402771"
      },
      "source": [
        "output = model.predict(X_test)\n",
        "print(output.shape)\n",
        "output = np.rint(output)\n",
        "result = np.concatenate((output.reshape(len(output),1), y_test.reshape(len(y_test),1)),1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1375, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQsGqxj8Ntkw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e167483d-bf07-4e9b-d9a1-f52c8c4ac14f"
      },
      "source": [
        "print(result[-50:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 5.  6.]\n",
            " [ 8.  8.]\n",
            " [ 9.  8.]\n",
            " [ 1.  1.]\n",
            " [ 8.  8.]\n",
            " [ 8.  8.]\n",
            " [ 6.  5.]\n",
            " [ 8.  7.]\n",
            " [ 3.  2.]\n",
            " [ 4.  5.]\n",
            " [ 6.  6.]\n",
            " [ 3.  3.]\n",
            " [ 9.  9.]\n",
            " [ 6.  6.]\n",
            " [ 6.  6.]\n",
            " [ 9.  9.]\n",
            " [ 3.  3.]\n",
            " [ 4.  4.]\n",
            " [ 2.  2.]\n",
            " [ 8.  8.]\n",
            " [ 4.  3.]\n",
            " [ 5.  5.]\n",
            " [ 6.  6.]\n",
            " [ 7.  7.]\n",
            " [ 9.  9.]\n",
            " [ 7.  8.]\n",
            " [ 1.  1.]\n",
            " [ 1.  1.]\n",
            " [ 6.  6.]\n",
            " [ 5.  5.]\n",
            " [ 8. 10.]\n",
            " [ 4.  4.]\n",
            " [ 4.  4.]\n",
            " [ 6.  6.]\n",
            " [ 9.  7.]\n",
            " [ 2.  1.]\n",
            " [10. 10.]\n",
            " [ 2.  1.]\n",
            " [ 1.  1.]\n",
            " [ 1.  1.]\n",
            " [ 1.  1.]\n",
            " [ 9.  9.]\n",
            " [ 5.  5.]\n",
            " [ 7.  7.]\n",
            " [10. 10.]\n",
            " [ 4.  4.]\n",
            " [ 2.  2.]\n",
            " [ 7.  7.]\n",
            " [ 1.  1.]\n",
            " [ 4.  4.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckPlq8vAAuRQ",
        "outputId": "560dd957-24b5-4757-c7fa-0db804336cb1"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
        "cm = confusion_matrix(y_test, output)\n",
        "print(cm)\n",
        "accuracy_score(y_test, output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[227  20  10   2   0   0   0   0   0   0]\n",
            " [  0  79  25   8   1   0   0   0   0   0]\n",
            " [  0   6 103  12   0   0   1   0   0   0]\n",
            " [  0   1   3 102  21   4   0   0   0   0]\n",
            " [  0   0   1  12 107   7   0   0   0   0]\n",
            " [  0   1   0   8  20  97   7   2   1   0]\n",
            " [  0   0   0   1   2   5  99  21   5   0]\n",
            " [  0   2   1   0   0   0   9  95   8   1]\n",
            " [  0   0   1   0   0   0   4  17  94   3]\n",
            " [  0   0   0   0   0   1   2   6  17  93]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7970909090909091"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 605
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXD9mwy-FT9W",
        "outputId": "6b1b0b3d-fcd1-4ff7-ef5b-c2f1283e3cc4"
      },
      "source": [
        "f1_score(y_test, output, average='weighted')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8001206511160931"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 606
        }
      ]
    }
  ]
}